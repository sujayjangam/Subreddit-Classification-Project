{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e8c24b6",
   "metadata": {},
   "source": [
    "# Modeling and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080efcb",
   "metadata": {},
   "source": [
    "In the previous notebooks, we have cleaned, preprocessed and conducted EDA on our data. Now we will proceed to model our data using `LogisticRegression`, `NaiveBayes`, and `RandomForest`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96057777",
   "metadata": {},
   "source": [
    "We will be carrying out the following steps:\n",
    "\n",
    "1. [Stop Words Removal](#Stop-Words-Removal)\n",
    "2. [Getting our data reading for modeling](#Getting-our-data-ready-for-modeling)\n",
    "3. [Benchmark Model Score](#Benchmark-Model-Score)\n",
    "4. [Model Testing](#Model-Testing)\n",
    "    - [Logistic Regression](#Logistic-Regression)<br>\n",
    "    - [Multinomial Naive Bayes](#Naive-Bayes)<br>\n",
    "    - [Random Forest](#Random-Forest)<br>\n",
    "5. [Tuning Models](#Tuning-Models)\n",
    "6. [Further Tuning](#Further-Tuning)\n",
    "7. [Error Analysis](#Error-Analysis)\n",
    "8. [Rerun Modeling](#Rerun-Modeling)\n",
    "9. [Model Limitations](#Model-Limitations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d15ce",
   "metadata": {},
   "source": [
    "This is the fourth of four notebooks:\n",
    "1. [Subreddit Scraping](1_Subreddit_Scraping.ipynb)\n",
    "2. [Data Cleaning](2_Data_Cleaning.ipynb)\n",
    "3. [EDA on Cleaned Subreddits Data](3_EDA_on_Subreddits.ipynb)\n",
    "4. **Modeling and Conclusions (Current Notebook)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf56d52",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b7a1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "                            accuracy_score, precision_score, \\\n",
    "                            recall_score, make_scorer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7087b605",
   "metadata": {},
   "source": [
    "> Reading in the 2 subreddits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e43703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned data from r/keto\n",
    "keto = pd.read_csv('datasets/keto_cleaned.csv')\n",
    "\n",
    "# cleaned data from r/zerocarb\n",
    "zerocarb = pd.read_csv('datasets/zerocarb_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7907d62",
   "metadata": {},
   "source": [
    "# Stop Words Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad52e0",
   "metadata": {},
   "source": [
    "The very first step that we will take will be to remove stop words. These are words that will cause bias in our model, and we want to get rid of those words within reason. In addition to using the stop words in the CountVectorizer library and the TFID library, we will also add in those words that will indicate the subreddit the text is from strongly, e.g. 'Keto', 'Zero', 'Carb', etc.\n",
    "\n",
    "We will take a look at some of the most common words that occur within our 2 dataframes, and use those to compile a list of stop words. This will be an iterative process. We will use count vectorizer to help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "794e0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = list(CountVectorizer(stop_words='english').get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "716add2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(data, col, \n",
    "                  num_of_words=30, \n",
    "                  stop_words=[], \n",
    "                  n_gram=()):\n",
    "    \n",
    "    \"\"\"Accepts input of DataFrame, string column name, \n",
    "    number of words, existing stop words list, n_gram.\"\"\"\n",
    "    \n",
    "    # defining variable\n",
    "    stop_words = stop_words\n",
    "    \n",
    "    # check variable length and define vectorizer \n",
    "    # based on if statements\n",
    "    if len(stop_words) and len(n_gram):\n",
    "        cvec = CountVectorizer(stop_words=stop_words,\n",
    "                              ngram_range=(n_gram))\n",
    "    elif len(stop_words):\n",
    "        cvec = CountVectorizer(stop_words=stop_words)\n",
    "    elif len(n_gram):\n",
    "        cvec = CountVectorizer(ngram_range=(n_gram))\n",
    "    else:\n",
    "        cvec = CountVectorizer()\n",
    "        \n",
    "    # Vectorize our column        \n",
    "    X = data[col]\n",
    "    X_cvec = cvec.fit_transform(X)\n",
    "\n",
    "    # temp DataFrame for sake of creating top words\n",
    "    df = pd.DataFrame(X_cvec.todense(),\n",
    "                       columns=cvec.get_feature_names_out())\n",
    "    \n",
    "    # return the top n words\n",
    "    return df.sum().sort_values(ascending=False).head(num_of_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d677d94",
   "metadata": {},
   "source": [
    "#### Run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "a12f91a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['keto', 'just', 'weight', 'im', 'like', 'carbs', 'day', 'diet', 'eat',\n",
       "       'time', 'eating', 've', 'fat', 'know', 'feel', 'really', 'started',\n",
       "       'doing', 'ive', 'week', 'days', 'lost', 'want', 'carb', 'good',\n",
       "       'protein', 'food', 'months', 'calories', 'weeks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(keto, 'c_text', 30, custom_stop_words).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "623c8a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['just', 'meat', 'diet', 'like', 'eat', 'eating', 'fat', 'beef', 've',\n",
       "       'day', 'carnivore', 'zc', 'feel', 'carb', 'know', 'time', 'im',\n",
       "       'really', 'days', 'zero', 'good', 'don', 'people', 'weight', 'food',\n",
       "       'keto', 'way', 'think', 'want', 'week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(zerocarb, 'c_text', 30, custom_stop_words).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "4656618f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['keto diet', 'weight loss', 'doing keto', 'started keto', 'low carb',\n",
       "       'net carbs', 'feel like', 'lose weight', 'losing weight', 'blood sugar',\n",
       "       'years ago', 'carbs day', 'keto months', 'weeks ago',\n",
       "       'intermittent fasting', 'water weight', 'goal weight', 'calories day',\n",
       "       'keto flu', 'keto weeks', 'keto friendly', 'don want', 'start keto',\n",
       "       'don know', 'keto years', 'starting keto', 'blood pressure', 've keto',\n",
       "       'did keto', 'dont know'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(keto, 'c_text', 30, custom_stop_words, (2,2)).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "2edff782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['zero carb', 'ground beef', 'carnivore diet', 'feel like',\n",
       "       'weight loss', 'grass fed', 'low carb', 'don know', 'eating meat',\n",
       "       'red meat', 'way eating', 'eat meat', 'bone broth', 'carb diet',\n",
       "       'lose weight', 'don want', 'years ago', 'long time', '30 days',\n",
       "       'body fat', 'beef liver', 'just wondering', 'days ago', 'just eat',\n",
       "       'feel better', 'gt gt', 'hey guys', 've eating', 've tried',\n",
       "       've doing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(zerocarb, 'c_text', 30, custom_stop_words, (2,2)).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d748ba",
   "metadata": {},
   "source": [
    "Looking at the list above, we will add the following words to our custom stop word list:\n",
    "> 'keto', 'meat', 'carnivore', 'zero', 'carb', 'carbs', 'zerocarb'\n",
    "\n",
    "After error analysis of our model, we also added in the following: 'ketosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "22ff7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words += ['keto', 'meat', 'carnivore', 'zero', 'carb', 'carbs', 'zerocarb', 'ketosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896b8c2",
   "metadata": {},
   "source": [
    "#### Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "aebc250e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['just', 'weight', 'im', 'like', 'day', 'diet', 'eat', 'time', 'eating',\n",
       "       've', 'fat', 'know', 'feel', 'really', 'started', 'doing', 'ive',\n",
       "       'week', 'days', 'lost', 'want', 'good', 'protein', 'food', 'months',\n",
       "       'calories', 'weeks', 'sugar', 'going', 'don'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(keto, 'c_text', 30, custom_stop_words).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "13e7e278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['just', 'diet', 'like', 'eat', 'eating', 'fat', 'beef', 've', 'day',\n",
       "       'zc', 'feel', 'know', 'time', 'im', 'really', 'days', 'good', 'don',\n",
       "       'people', 'weight', 'food', 'way', 'think', 'want', 'week', 'going',\n",
       "       'eggs', 'water', 'started', 'lot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(zerocarb, 'c_text', 30, custom_stop_words).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a739e13",
   "metadata": {},
   "source": [
    "Looking at the list above, we will add the following words to our custom stop word list:\n",
    "> 'zc', 'beef', 'eggs', 'sugar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "a306feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words += ['zc', 'beef', 'eggs', 'sugar']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dd46c",
   "metadata": {},
   "source": [
    "Now we will do one last check on bigrams to see if we can get any further insight into words we should remove from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "223257d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weight loss', 'feel like', 'lose weight', 'losing weight', 'years ago',\n",
       "       'weeks ago', 'intermittent fasting', 'water weight', 'goal weight',\n",
       "       'calories day', 'don want', 'don know', 'blood pressure', 'dont know',\n",
       "       'make sure', 'thanks advance', 'days week', 'lost weight', 'body fat',\n",
       "       'im just', 've doing', 'ive lost', 'feel better', 'just wanted',\n",
       "       'dont want', 'long term', 'ice cream', 'days ago', 've lost',\n",
       "       'months ago'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(keto, 'c_text', 30, custom_stop_words, (2,2)).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "e75dd60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feel like', 'weight loss', 'grass fed', 'don know', 'way eating',\n",
       "       'bone broth', 'lose weight', 'don want', 'years ago', 'long time',\n",
       "       '30 days', 'body fat', 'just wondering', 'days ago', 'gt gt',\n",
       "       'just eat', 'feel better', 'hey guys', 've eating', 've tried',\n",
       "       've doing', 'salt water', 'little bit', 'high fat', 'organ meats',\n",
       "       'thanks advance', 'felt like', 'heavy cream', 'months ago',\n",
       "       'feel great'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(zerocarb, 'c_text', 30, custom_stop_words, (2,2)).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10471c76",
   "metadata": {},
   "source": [
    "From the above, we can see that there are quite a few words more that we should add into our `custom_stop_words` list. Let's do that now.\n",
    "> 'intermittent', 'fasting', 'blood', 'pressure', 'ice', 'cream', 'bone', 'broth', 'organ', 'meats', 'heavy', 'cream', 'gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "876b748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words += ['intermittent', 'fasting', 'blood', 'pressure', \n",
    "                      'ice', 'cream', 'bone', 'broth', 'organ', 'meats', \n",
    "                      'heavy', 'cream', 'gt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580bef0",
   "metadata": {},
   "source": [
    "#### Run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "aa9eabe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weight loss', 'feel like', 'lose weight', 'losing weight', 'years ago',\n",
       "       'weeks ago', 'water weight', 'goal weight', 'calories day', 'don want',\n",
       "       'don know', 'dont know', 'make sure', 'thanks advance', 'days week',\n",
       "       'lost weight', 'body fat', 'im just', 've doing', 'ive lost',\n",
       "       'feel better', 'just wanted', 'dont want', 'long term', 'days ago',\n",
       "       've lost', 'months ago', 'long time', 'just want', 'im doing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(keto, 'c_text', 30, custom_stop_words, (2,2)).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "c0e6b944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feel like', 'weight loss', 'grass fed', 'don know', 'way eating',\n",
       "       'lose weight', 'don want', 'years ago', 'long time', '30 days',\n",
       "       'body fat', 'just wondering', 'days ago', 'just eat', 'feel better',\n",
       "       'hey guys', 've eating', 've tried', 've doing', 'salt water',\n",
       "       'little bit', 'high fat', 'thanks advance', 'felt like', 'months ago',\n",
       "       'feel great', 'long term', 'brain fog', 'weeks ago', 'just curious'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(zerocarb, 'c_text', 30, custom_stop_words, (2,2)).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "f8c048c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = pd.DataFrame(custom_stop_words, columns=['words'])\n",
    "custom_stop_words.to_csv('datasets/custom_stop_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd31dd",
   "metadata": {},
   "source": [
    "Now we have our stop words list and we are ready to use it in our modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326e9d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea075c5",
   "metadata": {},
   "source": [
    "# Getting our data ready for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e4bfd2",
   "metadata": {},
   "source": [
    "In order to start modeling on our dataset, we will need to merge our two different dataframes into 1 dataframe to feed into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "e84170d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat our 2 datasets\n",
    "df = pd.concat([keto, zerocarb], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d8f3e",
   "metadata": {},
   "source": [
    "After merging the two dataframes, we should be left with a new dataframe with 14 columns. Let's check this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db92c027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19669, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe39736",
   "metadata": {},
   "source": [
    "Next we will adjust the values in the `subreddit` column to take 1s and 0s. <br>\n",
    "1 will denote `r/keto`, and 0 will denote `r/zerocarb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cbd3d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keto        0.5015\n",
       "zerocarb    0.4985\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ratio of 'r/keot' vs 'r/zerocarb' before mapping\n",
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "427887e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map 1 if keto and 0 if not keto (i.e. 0 if zerocarb)\n",
    "df['subreddit'] = df['subreddit'].map(\n",
    "                                    lambda x: 1 if x == 'zerocarb'\n",
    "                                    else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a9fafa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5015\n",
       "1    0.4985\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check to ensure mapping is done correctly\n",
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7b03648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'subreddit' column to make model evaluation later easier\n",
    "df.rename(columns={'subreddit': 'is_zerocarb'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56c0c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unecessary columns to make our merged DataFrame lighter\n",
    "df.drop(columns=['num_comments', 'score', 'upvote_ratio',\n",
    "                 'subreddit_subscribers', 'subreddit_type', \n",
    "                 'total_awards_received', 'whitelist_status',\n",
    "                 'month_year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "055c1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets/merged_for_modeling.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc3fb3",
   "metadata": {},
   "source": [
    "With a custom list of stop words, and our merged dataset, we are now ready to begin modeling. In terms of re-running models when we come back to this notebook in the future, we would be able to skip all the above steps, and just read in the merged DataFrame and simply begin modeling from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcab119",
   "metadata": {},
   "source": [
    "# Benchmark Model Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc693209",
   "metadata": {},
   "source": [
    "We will build a simple Multinomial Naive Bayes model, with the CountVectorizer, with removal of our `custom_stop_words` list to get our baseline score that we will measure our other models against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "0a7a94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-read in our merged DataFrame and custom_stop_words\n",
    "df = pd.read_csv('datasets/merged_for_modeling.csv')\n",
    "\n",
    "custom_stop_words = pd.read_csv('datasets/custom_stop_words.csv')\n",
    "custom_stop_words = custom_stop_words['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d008a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting train_test_split for our baseline model\n",
    "# this train_test_split will be used for ALL our models\n",
    "X = df['c_text']\n",
    "y = df['is_zerocarb']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4cc8c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pipeline for baseline model\n",
    "pipe_baseline = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words=custom_stop_words)),\n",
    "    ('nb', MultinomialNB())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d4219ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(stop_words=['amoungst', 'rather', 'everyone',\n",
       "                                             'either', 'upon', 'which',\n",
       "                                             'amount', 'when', 'least', 'from',\n",
       "                                             'mostly', 'thereby', 'nobody',\n",
       "                                             'inc', 'still', 'has', 'twelve',\n",
       "                                             'were', 'about', 'between',\n",
       "                                             'formerly', 'through', 'put',\n",
       "                                             'with', 'ours', 'take', 'himself',\n",
       "                                             'often', 'thereafter', 'can', ...])),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting our model\n",
    "pipe_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dbbddc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856053384175405"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training score\n",
    "pipe_baseline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "043b277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274021352313167"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing score\n",
    "pipe_baseline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bfd5f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1756\n",
      "False Positives: 217\n",
      "False Negatives: 462\n",
      "True Positives: 1499\n"
     ]
    }
   ],
   "source": [
    "# baseline predictions to create confusion matrix\n",
    "bm_predictions = pipe_baseline.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, bm_predictions).ravel()\n",
    "\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "print(f'True Positives: {tp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc62db3",
   "metadata": {},
   "source": [
    "We now have a baseline score of **82.7%** which we will measure our other models against, and attempt to create the best model via fine tuning our hyper parameters and other adjustments to the model.\n",
    "\n",
    "As a side note, we can see that our baseline model is definitely overfit as the score on our training data is **89%**, however the score on our test data is **83%**. We will attempt to address this as we select the best models and we tune our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cca6be",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53d52b",
   "metadata": {},
   "source": [
    "For this section of the notebook, we will be mainly focusing on three model types:<br>\n",
    "*each model will use random_state 42(where possible), so that we can repeat the model performance which makes for easier comparison*\n",
    "\n",
    "[1. Logistic Regression](#Logistic-Regression)<br>\n",
    "[2. Multinomial Naive Bayes](#Naive-Bayes)<br>\n",
    "[3. Random Forest Trees](#Random_Forest_Trees)<br>\n",
    "\n",
    "For each of them, we will attempt to get the best possible model performance by tuning the model, and at the end will will compare the best model from each type. Following which we will attempt further tuning if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ecf2f6",
   "metadata": {},
   "source": [
    "For this section, we opted to creat a custom function that will fit our model, and add the results to a list, which we can view and compare across different models. For this function, we will instatiate all our vectorizers, models, and parameters which can be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "49d59728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate vectorizers\n",
    "vectorizers = {'cvec': CountVectorizer(stop_words=custom_stop_words),\n",
    "               'tvec': TfidfVectorizer(stop_words=custom_stop_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "a0374ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = {'lr': LogisticRegression(max_iter=1_000, random_state=42),\n",
    "          'nb': MultinomialNB(),\n",
    "          'rf': RandomForestClassifier(random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "508e1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2','l1'],\n",
    "\n",
    "     # Trying different C of: 10, 1, 0.1 (C = 1/alpha)\n",
    "    'lr__C':[0.1, 1, 10, 11]\n",
    "}\n",
    "\n",
    "nb_params = { \n",
    "    # Trying different fit priors\n",
    "    'nb__fit_prior': [True, False],\n",
    "    \n",
    "    # Trying different types of alpha\n",
    "    'nb__alpha': [0, 0.4, 0.8]\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'rf__n_estimators': [100, 200, 300],\n",
    "    'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'rf__max_features': ['sqrt', 'log2', 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "7aeb0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_params = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'cvec__max_features': [None, 10_000],\n",
    "\n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'cvec__min_df':[2, 3, 4],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus \n",
    "    'cvec__max_df': [0.4, 0.5, 0.8],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'cvec__ngram_range':[(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "tvec_params = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None, 10_000],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[2, 3, 4],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.4, 0.5, 0.8],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "ea37618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run model -- input vectorizer and model\n",
    "def get_model_scores(model_name, \n",
    "                     vec, \n",
    "                     mod, \n",
    "                     vec_params={}, \n",
    "                     mod_params={}, \n",
    "                     grid_search=False):\n",
    "    \n",
    "    \"\"\"Function accepts following inputs:\n",
    "    Name of model (str), vectorizer to be used (str), \n",
    "    model to be used (str), vectorizer params(dict, optional), \n",
    "    model params(dict, optional), grid_seach(boolean, optional)\n",
    "    If grid_search is True, then please also input the relevant \n",
    "    params for GridSearching\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty dict for appending results\n",
    "    results = {}\n",
    "    \n",
    "    # instantiate pipe\n",
    "    pipe = Pipeline([\n",
    "            (vec, vectorizers[vec]),\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    # check if GridSearch true or false\n",
    "    if grid_search:\n",
    "        \n",
    "        # combine vectorizer and mod params together\n",
    "        gs_params = {}\n",
    "        gs_params.update(vec_params)\n",
    "        gs_params.update(mod_params)\n",
    "        \n",
    "        # instantiate GridSearchCV\n",
    "        gs = GridSearchCV(pipe, \n",
    "                          param_grid=gs_params,\n",
    "                          cv=5, \n",
    "                          verbose=2, \n",
    "                          n_jobs=-2)\n",
    "        \n",
    "        # fit model\n",
    "        gs.fit(X_train, y_train)\n",
    "        pipe = gs\n",
    "        \n",
    "    else:\n",
    "        # else fit model\n",
    "        pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # create predictions and confusion matrix\n",
    "    predictions = pipe.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    # Retrieve metrics and add to results\n",
    "    results['model_name'] = model_name\n",
    "    results['model'] = mod\n",
    "    results['vectorizer'] = vec\n",
    "    results['train_score'] = pipe.score(X_train, y_train)\n",
    "    results['test_score'] = pipe.score(X_test, y_test)\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, \n",
    "                                     predictions)\n",
    "    \n",
    "    results['true_neg_rate'] = tn/(tn+fp)\n",
    "    \n",
    "    results['precision'] = precision_score(y_test, \n",
    "                                           predictions)\n",
    "    results['is_tuned'] = grid_search\n",
    "    \n",
    "    if grid_search:\n",
    "        print('BEST PARAMS-->')\n",
    "        display(pipe.best_params_)\n",
    "    \n",
    "    # add results to list for model evaluation later\n",
    "    model_eval.append(results)\n",
    "    \n",
    "    print('METRICS-->')\n",
    "    display(results)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bd71491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list to store the model scores.\n",
    "model_eval = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44d13d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570071a",
   "metadata": {},
   "source": [
    "We will be testing both CountVectorizer and TfidfVectorizer for each model, without any tuning of hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36112fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'cvec_lr',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'cvec',\n",
       " 'train_score': 0.9883063234826819,\n",
       " 'test_score': 0.8362989323843416,\n",
       " 'recall': 0.8449770525242223,\n",
       " 'true_neg_rate': 0.8276735935124176,\n",
       " 'precision': 0.829744616925388,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1633\n",
      "False Positives: 340\n",
      "False Negatives: 304\n",
      "True Positives: 1657\n"
     ]
    }
   ],
   "source": [
    "cvec_lr = get_model_scores('cvec_lr', \n",
    "                           'cvec', \n",
    "                           'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c131cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_lr',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9103908484270734,\n",
       " 'test_score': 0.8474834773767158,\n",
       " 'recall': 0.8342682304946456,\n",
       " 'true_neg_rate': 0.8606183476938672,\n",
       " 'precision': 0.8560962846677133,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1698\n",
      "False Positives: 275\n",
      "False Negatives: 325\n",
      "True Positives: 1636\n"
     ]
    }
   ],
   "source": [
    "tvec_lr = get_model_scores('tvec_lr',\n",
    "                           'tvec', \n",
    "                           'lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fdb2a4",
   "metadata": {},
   "source": [
    "Without any sort of tuning, we can see that the `TfidfVectorizer` has improved our score from the baseline score of **83.6%**, to now **84.7%**. Let's now take a look at Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f1114",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad491543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'cvec_nb',\n",
       " 'model': 'nb',\n",
       " 'vectorizer': 'cvec',\n",
       " 'train_score': 0.8955830950111217,\n",
       " 'test_score': 0.8304524656837824,\n",
       " 'recall': 0.8077511473737888,\n",
       " 'true_neg_rate': 0.8530157121135327,\n",
       " 'precision': 0.8452508004268944,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1683\n",
      "False Positives: 290\n",
      "False Negatives: 377\n",
      "True Positives: 1584\n"
     ]
    }
   ],
   "source": [
    "cvec_nb = get_model_scores('cvec_nb',\n",
    "                           'cvec', \n",
    "                           'nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fc172eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_nb',\n",
       " 'model': 'nb',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.8856053384175405,\n",
       " 'test_score': 0.8274021352313167,\n",
       " 'recall': 0.7644059153493116,\n",
       " 'true_neg_rate': 0.8900152052711606,\n",
       " 'precision': 0.8735431235431236,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1756\n",
      "False Positives: 217\n",
      "False Negatives: 462\n",
      "True Positives: 1499\n"
     ]
    }
   ],
   "source": [
    "tvec_nb = get_model_scores('tvec_nb', \n",
    "                           'tvec', \n",
    "                           'nb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0bd3c",
   "metadata": {},
   "source": [
    "In the case of Naive Bayes, it turns out that the `CountVectorizer` led to a better performance, however this performs below our base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b78b16d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05bcf4",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90d5d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'cvec_rf',\n",
       " 'model': 'rf',\n",
       " 'vectorizer': 'cvec',\n",
       " 'train_score': 1.0,\n",
       " 'test_score': 0.8256227758007118,\n",
       " 'recall': 0.815910249872514,\n",
       " 'true_neg_rate': 0.8352762290927521,\n",
       " 'precision': 0.8311688311688312,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1648\n",
      "False Positives: 325\n",
      "False Negatives: 361\n",
      "True Positives: 1600\n"
     ]
    }
   ],
   "source": [
    "cvec_rf = get_model_scores('cvec_rf', \n",
    "                           'cvec', \n",
    "                           'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8bc3f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_rf',\n",
       " 'model': 'rf',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 1.0,\n",
       " 'test_score': 0.8274021352313167,\n",
       " 'recall': 0.8052014278429372,\n",
       " 'true_neg_rate': 0.8494678155093766,\n",
       " 'precision': 0.841684434968017,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1676\n",
      "False Positives: 297\n",
      "False Negatives: 382\n",
      "True Positives: 1579\n"
     ]
    }
   ],
   "source": [
    "tvec_rf = get_model_scores('tvec_rf', \n",
    "                           'tvec', \n",
    "                           'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4023b8",
   "metadata": {},
   "source": [
    "Now let's take a look at tuning our best performing models. Based on the above, we will tune `LogisticRegression` with `TfidfVectorizer`, as well as `NaiveBayes` with `CountVectorizer`, and `TfidfVectorizer`, and `RandomForest` with `TfidfVectorizer`. <br>\n",
    "This is based on the `accuracy` scores as well as the `precision` scores, of which `precision` is the most relevant to our problem statment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be00824",
   "metadata": {},
   "source": [
    "# Tuning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c4d6e",
   "metadata": {},
   "source": [
    "At a later part of the notebook, during error analysis, we realized that there was a critical stop word that had not been removed, so we removed that, and refit the base models, as well as did tuning to get our final model again, so please take these models here with a grain of salt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "07e92d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "720 fits failed out of a total of 1440.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.81804894 0.81544328 0.82059104 0.8171592  0.82071814 0.81912933\n",
      " 0.82014617 0.82109946 0.82065459 0.82116301 0.82020972 0.8209088\n",
      " 0.81804894 0.81544328 0.82059104 0.8171592  0.82071814 0.81912933\n",
      " 0.82014617 0.82109946 0.82065459 0.82116301 0.82020972 0.8209088\n",
      " 0.81804894 0.81544328 0.82059104 0.8171592  0.82071814 0.81912933\n",
      " 0.82014617 0.82109946 0.82065459 0.82116301 0.82020972 0.8209088\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84721957 0.84747378 0.84760089 0.84931681 0.84696536 0.84861773\n",
      " 0.84715602 0.84791865 0.84677471 0.84836352 0.84696536 0.84823642\n",
      " 0.84721957 0.84747378 0.84760089 0.84931681 0.84696536 0.84861773\n",
      " 0.84715602 0.84791865 0.84677471 0.84836352 0.84696536 0.84823642\n",
      " 0.84721957 0.84747378 0.84760089 0.84931681 0.84696536 0.84861773\n",
      " 0.84715602 0.84791865 0.84677471 0.84836352 0.84696536 0.84823642\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83952971 0.85109628 0.83819511 0.84772799 0.83876708 0.84632984\n",
      " 0.8379409  0.83781379 0.83813155 0.83775024 0.83844932 0.8379409\n",
      " 0.83952971 0.85109628 0.83819511 0.84772799 0.83876708 0.84632984\n",
      " 0.8379409  0.83781379 0.83813155 0.83775024 0.83844932 0.8379409\n",
      " 0.83952971 0.85109628 0.83819511 0.84772799 0.83876708 0.84632984\n",
      " 0.8379409  0.83781379 0.83813155 0.83775024 0.83844932 0.8379409\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83851287 0.8502701  0.83775024 0.84734668 0.83787734 0.84569431\n",
      " 0.83724182 0.83698761 0.83724182 0.8367334  0.83705116 0.83775024\n",
      " 0.83851287 0.8502701  0.83775024 0.84734668 0.83787734 0.84569431\n",
      " 0.83724182 0.83698761 0.83724182 0.8367334  0.83705116 0.83775024\n",
      " 0.83851287 0.8502701  0.83775024 0.84734668 0.83787734 0.84569431\n",
      " 0.83724182 0.83698761 0.83724182 0.8367334  0.83705116 0.83775024\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 10,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 0.4,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_lr_gs',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9971401334604385,\n",
       " 'test_score': 0.8472292831723437,\n",
       " 'recall': 0.8291687914329424,\n",
       " 'true_neg_rate': 0.8651799290420679,\n",
       " 'precision': 0.8594080338266384,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1707\n",
      "False Positives: 266\n",
      "False Negatives: 335\n",
      "True Positives: 1626\n"
     ]
    }
   ],
   "source": [
    "tvec_lr_gs = get_model_scores('tvec_lr_gs', \n",
    "                              'tvec', \n",
    "                              'lr', \n",
    "                              vec_params=tvec_params, \n",
    "                              mod_params=lr_params, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a42546",
   "metadata": {},
   "source": [
    "We saw a 0.3% improvement in the `precision` score, however there was a drop in the `accuracy` score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f2048c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.4,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'nb__alpha': 0.8,\n",
       " 'nb__fit_prior': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'cvec_nb_gs',\n",
       " 'model': 'nb',\n",
       " 'vectorizer': 'cvec',\n",
       " 'train_score': 0.9220845249443915,\n",
       " 'test_score': 0.8396034570411794,\n",
       " 'recall': 0.842937276899541,\n",
       " 'true_neg_rate': 0.8362899138367967,\n",
       " 'precision': 0.8365384615384616,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1650\n",
      "False Positives: 323\n",
      "False Negatives: 308\n",
      "True Positives: 1653\n"
     ]
    }
   ],
   "source": [
    "cvec_nb_gs = get_model_scores('cvec_nb_gs', \n",
    "                              'cvec', \n",
    "                              'nb', \n",
    "                              vec_params=cvec_params, \n",
    "                              mod_params=nb_params, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4aee9d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 0.4,\n",
       " 'nb__fit_prior': False,\n",
       " 'tvec__max_df': 0.4,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 4,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_nb_gs',\n",
       " 'model': 'nb',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.921258341277407,\n",
       " 'test_score': 0.8383324860193188,\n",
       " 'recall': 0.8291687914329424,\n",
       " 'true_neg_rate': 0.8474404460212874,\n",
       " 'precision': 0.843798650752465,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1672\n",
      "False Positives: 301\n",
      "False Negatives: 335\n",
      "True Positives: 1626\n"
     ]
    }
   ],
   "source": [
    "tvec_nb_gs = get_model_scores('tvec_nb_gs', \n",
    "                              'tvec', \n",
    "                              'nb', \n",
    "                              vec_params=tvec_params, \n",
    "                              mod_params=nb_params, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafbcaf",
   "metadata": {},
   "source": [
    "For the `cvec` and `NaiveBayes` model, we saw a deprovement in `precision` score and an improvement in `accuracy` score. For the `tvec` and `NaiveBayes` model, we saw a larger drop in `precision` score and a drop in `accuracy` as well.\n",
    "For this reason we will most likely pick the `LogisticRegression` model. However we will still attempt fine tuning of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb11496",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36409d",
   "metadata": {},
   "source": [
    "For our `RandomForest` model, running it via `GridsearchCV` will take quite some time, as such we will opt to use `RandomSearchCV` instead. Since we have already written a function previously, we will just rewrite the function and replace `GridSearchCV` with `RandomSearchCV` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c183b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run model, exactly same as before, \n",
    "# only with randomized search\n",
    "def get_model_scores_rfe(model_name, \n",
    "                         vec, \n",
    "                         mod, \n",
    "                         vec_params={}, \n",
    "                         mod_params={}, \n",
    "                         random_search=False):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "            (vec, vectorizers[vec]),\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    if random_search:\n",
    "        rs_params = {}\n",
    "        rs_params.update(vec_params)\n",
    "        rs_params.update(mod_params)\n",
    "        \n",
    "        rs = RandomizedSearchCV(pipe, \n",
    "                                param_distributions=rs_params, \n",
    "                                cv=5, \n",
    "                                verbose=2, \n",
    "                                n_jobs=-2)\n",
    "        \n",
    "        rs.fit(X_train, y_train)\n",
    "        pipe = rs\n",
    "        \n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = pipe.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    # Retrieve metrics\n",
    "    results['model_name'] = model_name\n",
    "    results['model'] = mod\n",
    "    results['vectorizer'] = vec\n",
    "    results['train_score'] = pipe.score(X_train, y_train)\n",
    "    results['test_score'] = pipe.score(X_test, y_test)\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, \n",
    "                                     predictions)\n",
    "    \n",
    "    results['true_neg_rate'] = tn/(tn+fp)\n",
    "    results['precision'] = precision_score(y_test, \n",
    "                                           predictions)\n",
    "    results['is_tuned'] = random_search\n",
    "    \n",
    "    if random_search:\n",
    "        print('BEST PARAMS-->')\n",
    "        display(pipe.best_params_)\n",
    "        \n",
    "    model_eval.append(results)\n",
    "    \n",
    "    print('METRICS-->')\n",
    "    display(results)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "76baaf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__ngram_range': (1, 2),\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__max_features': 10000,\n",
       " 'tvec__max_df': 0.4,\n",
       " 'rf__n_estimators': 300,\n",
       " 'rf__max_features': 0.5,\n",
       " 'rf__max_depth': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_rb_rs',\n",
       " 'model': 'rf',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 1.0,\n",
       " 'test_score': 0.7956278596847992,\n",
       " 'recall': 0.7582865884752678,\n",
       " 'true_neg_rate': 0.8327420172326406,\n",
       " 'precision': 0.8183819482663731,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1643\n",
      "False Positives: 330\n",
      "False Negatives: 474\n",
      "True Positives: 1487\n"
     ]
    }
   ],
   "source": [
    "tvec_rb_rs = get_model_scores_rfe('tvec_rb_rs', \n",
    "                                  'tvec', \n",
    "                                  'rf', \n",
    "                                  vec_params=tvec_params, \n",
    "                                  mod_params=rf_params, \n",
    "                                  random_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80d64d",
   "metadata": {},
   "source": [
    "In this case, our `RandomForests` has performed worse on both metrics that we are interested in. In the interest of getting a minimum viable model up and running for 'MyNutritionClinic', we will opt to choose a model that will be quicker to tune and get ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2399defd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>true_neg_rate</th>\n",
       "      <th>precision</th>\n",
       "      <th>is_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cvec_lr</td>\n",
       "      <td>lr</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.988306</td>\n",
       "      <td>0.836299</td>\n",
       "      <td>0.844977</td>\n",
       "      <td>0.827674</td>\n",
       "      <td>0.829745</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tvec_lr</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.910391</td>\n",
       "      <td>0.847483</td>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.860618</td>\n",
       "      <td>0.856096</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cvec_nb</td>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.895583</td>\n",
       "      <td>0.830452</td>\n",
       "      <td>0.807751</td>\n",
       "      <td>0.853016</td>\n",
       "      <td>0.845251</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tvec_nb</td>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.885605</td>\n",
       "      <td>0.827402</td>\n",
       "      <td>0.764406</td>\n",
       "      <td>0.890015</td>\n",
       "      <td>0.873543</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cvec_rf</td>\n",
       "      <td>rf</td>\n",
       "      <td>cvec</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>0.815910</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tvec_rf</td>\n",
       "      <td>rf</td>\n",
       "      <td>tvec</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827402</td>\n",
       "      <td>0.805201</td>\n",
       "      <td>0.849468</td>\n",
       "      <td>0.841684</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tvec_lr_gs</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.997140</td>\n",
       "      <td>0.847229</td>\n",
       "      <td>0.829169</td>\n",
       "      <td>0.865180</td>\n",
       "      <td>0.859408</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cvec_nb_gs</td>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.922085</td>\n",
       "      <td>0.839603</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>0.836290</td>\n",
       "      <td>0.836538</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tvec_rb_rs</td>\n",
       "      <td>rf</td>\n",
       "      <td>tvec</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795628</td>\n",
       "      <td>0.758287</td>\n",
       "      <td>0.832742</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tvec_nb_gs</td>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.921258</td>\n",
       "      <td>0.838332</td>\n",
       "      <td>0.829169</td>\n",
       "      <td>0.847440</td>\n",
       "      <td>0.843799</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name model vectorizer  train_score  test_score    recall  \\\n",
       "0     cvec_lr    lr       cvec     0.988306    0.836299  0.844977   \n",
       "1     tvec_lr    lr       tvec     0.910391    0.847483  0.834268   \n",
       "2     cvec_nb    nb       cvec     0.895583    0.830452  0.807751   \n",
       "3     tvec_nb    nb       tvec     0.885605    0.827402  0.764406   \n",
       "4     cvec_rf    rf       cvec     1.000000    0.825623  0.815910   \n",
       "5     tvec_rf    rf       tvec     1.000000    0.827402  0.805201   \n",
       "6  tvec_lr_gs    lr       tvec     0.997140    0.847229  0.829169   \n",
       "7  cvec_nb_gs    nb       cvec     0.922085    0.839603  0.842937   \n",
       "8  tvec_rb_rs    rf       tvec     1.000000    0.795628  0.758287   \n",
       "9  tvec_nb_gs    nb       tvec     0.921258    0.838332  0.829169   \n",
       "\n",
       "   true_neg_rate  precision  is_tuned  \n",
       "0       0.827674   0.829745     False  \n",
       "1       0.860618   0.856096     False  \n",
       "2       0.853016   0.845251     False  \n",
       "3       0.890015   0.873543     False  \n",
       "4       0.835276   0.831169     False  \n",
       "5       0.849468   0.841684     False  \n",
       "6       0.865180   0.859408      True  \n",
       "7       0.836290   0.836538      True  \n",
       "8       0.832742   0.818382      True  \n",
       "9       0.847440   0.843799      True  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scoresV1 = pd.DataFrame(model_eval)\n",
    "model_scoresV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "88606ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>test_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>is_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tvec_nb</td>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.827402</td>\n",
       "      <td>0.873543</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tvec_lr_gs</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.847229</td>\n",
       "      <td>0.859408</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tvec_lr</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.847483</td>\n",
       "      <td>0.856096</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cvec_nb</td>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.830452</td>\n",
       "      <td>0.845251</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tvec_nb_gs</td>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.838332</td>\n",
       "      <td>0.843799</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name model vectorizer  test_score  precision  is_tuned\n",
       "3     tvec_nb    nb       tvec    0.827402   0.873543     False\n",
       "6  tvec_lr_gs    lr       tvec    0.847229   0.859408      True\n",
       "1     tvec_lr    lr       tvec    0.847483   0.856096     False\n",
       "2     cvec_nb    nb       cvec    0.830452   0.845251     False\n",
       "9  tvec_nb_gs    nb       tvec    0.838332   0.843799      True"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the top 5 models so far by precision score and accuracy score\n",
    "model_scoresV1.drop(columns=['train_score', 'recall', 'true_neg_rate'])\\\n",
    ".sort_values(by=['precision', 'test_score'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72c221",
   "metadata": {},
   "source": [
    "From the above table, we can see that the base `TfidfVectorizer` with `NaiveBayes` has the best precision performance, but the poorest `accuracy` performance. We can also see that the `LogisticRegression` with `TfidfVectorizer` is not far behind in terms of `precision` however it does about 2% better in terms of `accuracy`. We will conduct further tuning on these two models to choose our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50070831",
   "metadata": {},
   "source": [
    "# Further Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d425d",
   "metadata": {},
   "source": [
    "First let's adjust the parameters that we will use for `GridSearchCV` in hopes of tuning our model.\n",
    "We will rewrite the function to add in a scoring parameter that will help us to improve the precision and accuracy score of our model.\n",
    "\n",
    "This will be a repetitive and iterative process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1677b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact same function as before, \n",
    "# just added the line before that is commented on\n",
    "def get_model_scores_V2(model_name, \n",
    "                     vec, \n",
    "                     mod, \n",
    "                     vec_params={}, \n",
    "                     mod_params={}, \n",
    "                     grid_search=False):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "            (vec, vectorizers[vec]),\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    if grid_search:\n",
    "        gs_params = {}\n",
    "        gs_params.update(vec_params)\n",
    "        gs_params.update(mod_params)\n",
    "        \n",
    "        # adding in scoring parameters\n",
    "        scoring = {'Precision': make_scorer(precision_score),\n",
    "                   'Accuracy': make_scorer(accuracy_score)}\n",
    "        \n",
    "        gs = GridSearchCV(pipe, \n",
    "                          param_grid=gs_params,\n",
    "                          scoring=scoring,\n",
    "                          refit='Accuracy',\n",
    "                          cv=5, \n",
    "                          verbose=2, \n",
    "                          n_jobs=-2)\n",
    "        \n",
    "        gs.fit(X_train, y_train)\n",
    "        pipe = gs\n",
    "        \n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = pipe.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    # Retrieve metrics\n",
    "    results['model_name'] = model_name\n",
    "    results['model'] = mod\n",
    "    results['vectorizer'] = vec\n",
    "    results['train_score'] = pipe.score(X_train, y_train)\n",
    "    results['test_score'] = pipe.score(X_test, y_test)\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, \n",
    "                                     predictions)\n",
    "    \n",
    "    results['true_neg_rate'] = tn/(tn+fp)\n",
    "    \n",
    "    results['precision'] = precision_score(y_test, \n",
    "                                           predictions)\n",
    "    results['is_tuned'] = grid_search\n",
    "    \n",
    "    if grid_search:\n",
    "        print('BEST PARAMS-->')\n",
    "        display(pipe.best_params_)\n",
    "        \n",
    "    model_eval.append(results)\n",
    "    \n",
    "    print('METRICS-->')\n",
    "    display(results)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd317c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c88572",
   "metadata": {},
   "source": [
    "We will iterate through different versions of the models and attempt to change the parameters to improve the `precision` and `accuracy` scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6937c289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 0.4,\n",
       " 'nb__fit_prior': False,\n",
       " 'tvec__max_df': 0.4,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 4,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_nb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e0246719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-adjusting params based on previous run\n",
    "\n",
    "nb_params_V2 = {   \n",
    "    # Trying different types of alpha\n",
    "    'nb__alpha': [0.2, 0.3, 0.4]\n",
    "}\n",
    "\n",
    "tvec_nb_params_V2 = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None, 3000, 5000],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[4, 5],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.2, 0.3, 0.4],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1,2), (2,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b0be02dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 0.4,\n",
       " 'tvec__max_df': 0.2,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 4,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_nb_gs_V2',\n",
       " 'model': 'nb',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9224022878932316,\n",
       " 'test_score': 0.838840874428063,\n",
       " 'recall': 0.827129015808261,\n",
       " 'true_neg_rate': 0.8504815002534212,\n",
       " 'precision': 0.8461137193531559,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1678\n",
      "False Positives: 295\n",
      "False Negatives: 339\n",
      "True Positives: 1622\n"
     ]
    }
   ],
   "source": [
    "# Let's readjust the parameters based on these results\n",
    "tvec_nb_gs_V2 = get_model_scores_V2('tvec_nb_gs_V2', \n",
    "                                    'tvec', \n",
    "                                    'nb', \n",
    "                                    vec_params=tvec_nb_params_V2, \n",
    "                                    mod_params=nb_params_V2, \n",
    "                                    grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb43960",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7c9723ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-adjusting params based on previous run\n",
    "\n",
    "nb_params_V3 = {   \n",
    "    # Trying different types of alpha\n",
    "    'nb__alpha': [0.4, 0.5]\n",
    "}\n",
    "\n",
    "tvec_nb_params_V3 = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[3.5, 4, 4.5],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [None, 0.1, 0.2],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1,2), (2,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "583ecf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "140 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2077, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1313, in fit_transform\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1259, in _validate_params\n",
      "    check_scalar(self.min_df, \"min_df\", numbers.Real, min_val=0.0, max_val=1.0)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1329, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_df == 3.5, must be <= 1.0.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2077, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1313, in fit_transform\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1264, in _validate_params\n",
      "    check_scalar(self.max_df, \"max_df\", numbers.Real, min_val=0.0, max_val=1.0)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1307, in check_scalar\n",
      "    raise TypeError(f\"{name} must be an instance of {target_type}, not {type(x)}.\")\n",
      "TypeError: max_df must be an instance of <class 'numbers.Real'>, not <class 'NoneType'>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2077, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1313, in fit_transform\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1259, in _validate_params\n",
      "    check_scalar(self.min_df, \"min_df\", numbers.Real, min_val=0.0, max_val=1.0)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1329, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_df == 4.5, must be <= 1.0.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.8399849  0.76525676        nan        nan\n",
      "        nan        nan 0.8416078  0.76525676        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.84087834 0.76569346        nan        nan\n",
      "        nan        nan 0.84289485 0.76569346        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.83597077 0.76123292        nan        nan\n",
      "        nan        nan 0.83635208 0.76123292        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.83603432 0.76136003        nan        nan\n",
      "        nan        nan 0.83654274 0.76136003        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 0.5,\n",
       " 'tvec__max_df': 0.2,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 4,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_nb_gs_V3',\n",
       " 'model': 'nb',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9194153161741341,\n",
       " 'test_score': 0.8383324860193188,\n",
       " 'recall': 0.8225395206527282,\n",
       " 'true_neg_rate': 0.8540293968575773,\n",
       " 'precision': 0.8485007890583903,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1685\n",
      "False Positives: 288\n",
      "False Negatives: 348\n",
      "True Positives: 1613\n"
     ]
    }
   ],
   "source": [
    "# re-run model with adjusted parameters\n",
    "tvec_nb_gs_V3 = get_model_scores_V2('tvec_nb_gs_V3', \n",
    "                              'tvec', \n",
    "                              'nb', \n",
    "                              vec_params=tvec_nb_params_V3, \n",
    "                              mod_params=nb_params_V3, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0c9524",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "5f417819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-adjusting params based on previous run\n",
    "\n",
    "nb_params_V4 = {   \n",
    "    # Trying different types of alpha\n",
    "    'nb__alpha': [0.5, 0.6, 0.7]\n",
    "}\n",
    "\n",
    "tvec_nb_params_V4 = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[4],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.2],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1, 1), (1,2), (1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7fb539bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 0.5,\n",
       " 'tvec__max_df': 0.2,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 4,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_nb_gs_V4',\n",
       " 'model': 'nb',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9164918970448046,\n",
       " 'test_score': 0.8289273004575496,\n",
       " 'recall': 0.8092809790922999,\n",
       " 'true_neg_rate': 0.8484541307653319,\n",
       " 'precision': 0.8414634146341463,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1674\n",
      "False Positives: 299\n",
      "False Negatives: 374\n",
      "True Positives: 1587\n"
     ]
    }
   ],
   "source": [
    "# re-run model with adjusted parameters\n",
    "tvec_nb_gs_V4 = get_model_scores_V2('tvec_nb_gs_V4', \n",
    "                              'tvec', \n",
    "                              'nb', \n",
    "\n",
    "                                    vec_params=tvec_nb_params_V4, \n",
    "                              mod_params=nb_params_V4, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d908930",
   "metadata": {},
   "source": [
    "We believe that we have pushed this model as far as it can go in terms of balance between `accuracy` and `precision`.\n",
    "Now we will repeat this process for `LogisticRegression` and then we will take a look at the results again at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7e28a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "264c2089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 10,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 0.4,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_lr_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f5a949da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-adjusting parameters from previous run\n",
    "\n",
    "lr_params = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2'],\n",
    "\n",
    "     # Trying different C of:(C = 1/alpha)\n",
    "    'lr__C':[9.5, 10, 11]\n",
    "}\n",
    "\n",
    "tvec_params = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[1.5, 2, 2.5],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.2, 0.3, 0.4],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1,1), (1,2), (1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "f68d99f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 9.5,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_lr_gs_V2',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9965681601525263,\n",
       " 'test_score': 0.8439247585155059,\n",
       " 'recall': 0.8220295767465579,\n",
       " 'true_neg_rate': 0.8656867714140902,\n",
       " 'precision': 0.8588172615876398,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1708\n",
      "False Positives: 265\n",
      "False Negatives: 349\n",
      "True Positives: 1612\n"
     ]
    }
   ],
   "source": [
    "tvec_lr_gs_V2 = get_model_scores_V2('tvec_lr_gs_V2', \n",
    "                              'tvec', \n",
    "                              'lr', \n",
    "                              vec_params=tvec_lr_params_V2, \n",
    "                              mod_params=lr_params_V2, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de00a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "0fdab565",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_V3 = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2'],\n",
    "\n",
    "     # Trying different C of: 10, 1, 0.1 (C = 1/alpha)\n",
    "    'lr__C':[9, 9.25, 9.5]\n",
    "}\n",
    "\n",
    "tvec_lr_params_V3 = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[2],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.25, 0.3, 0.35],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1, 1), (1,2), (1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "24b0a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 9,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 0.35,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_lr_gs_V3',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9959326342548459,\n",
       " 'test_score': 0.8439247585155059,\n",
       " 'recall': 0.8240693523712391,\n",
       " 'true_neg_rate': 0.863659401926001,\n",
       " 'precision': 0.8572944297082228,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1704\n",
      "False Positives: 269\n",
      "False Negatives: 345\n",
      "True Positives: 1616\n"
     ]
    }
   ],
   "source": [
    "tvec_lr_gs_V3 = get_model_scores_V2('tvec_lr_gs_V3', \n",
    "                              'tvec', \n",
    "                              'lr', \n",
    "                              vec_params=tvec_lr_params_V3, \n",
    "                              mod_params=lr_params_V3, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e7feb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "4ad0cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_V4 = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2'],\n",
    "\n",
    "     # Trying different C of: 10, 1, 0.1 (C = 1/alpha)\n",
    "    'lr__C':[11]\n",
    "}\n",
    "\n",
    "tvec_lr_params_V4 = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[2],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.35, 0.36, 0.37],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ec46ad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 11,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 0.35,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_lr_gs_V4',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.998093422306959,\n",
       " 'test_score': 0.8434163701067615,\n",
       " 'recall': 0.8225395206527282,\n",
       " 'true_neg_rate': 0.8641662442980234,\n",
       " 'precision': 0.8575225943646996,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1705\n",
      "False Positives: 268\n",
      "False Negatives: 348\n",
      "True Positives: 1613\n"
     ]
    }
   ],
   "source": [
    "tvec_lr_gs_V4 = get_model_scores_V2('tvec_lr_gs_V4', \n",
    "                              'tvec', \n",
    "                              'lr', \n",
    "                              vec_params=tvec_lr_params_V4, \n",
    "                              mod_params=lr_params_V4, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6584a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "080f66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_V5 = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2'],\n",
    "\n",
    "     # Trying different C of: 10, 1, 0.1 (C = 1/alpha)\n",
    "    'lr__C':[5, 6, 7, 8, 9, 10, 11, 12]\n",
    "}\n",
    "\n",
    "tvec_lr_params_V5 = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[2],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.3, 0.35, 0.4],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "61857734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 5,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 0.35,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_lr_gs_V5',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9856371147124245,\n",
       " 'test_score': 0.8454499237417387,\n",
       " 'recall': 0.8245792962774094,\n",
       " 'true_neg_rate': 0.8661936137861125,\n",
       " 'precision': 0.8596491228070176,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1709\n",
      "False Positives: 264\n",
      "False Negatives: 344\n",
      "True Positives: 1617\n"
     ]
    }
   ],
   "source": [
    "tvec_lr_gs_V5 = get_model_scores_V2('tvec_lr_gs_V5', \n",
    "                              'tvec', \n",
    "                              'lr', \n",
    "                              vec_params=tvec_lr_params_V5, \n",
    "                              mod_params=lr_params_V5, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3107e2",
   "metadata": {},
   "source": [
    "We believe that we have pushed this model as far as it can go as well in terms of balance between `accuracy` and `precision`, and maximizing `precision`.\n",
    "Let's review the results between the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "20bf4725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>true_neg_rate</th>\n",
       "      <th>precision</th>\n",
       "      <th>is_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tvec_lr_gs_V5</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.985637</td>\n",
       "      <td>0.845450</td>\n",
       "      <td>0.824579</td>\n",
       "      <td>0.866194</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tvec_lr_gs_V2</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.996568</td>\n",
       "      <td>0.843925</td>\n",
       "      <td>0.822030</td>\n",
       "      <td>0.865687</td>\n",
       "      <td>0.858817</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tvec_lr_gs_V3</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.995933</td>\n",
       "      <td>0.843925</td>\n",
       "      <td>0.824069</td>\n",
       "      <td>0.863659</td>\n",
       "      <td>0.857294</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tvec_lr_gs_V4</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.995234</td>\n",
       "      <td>0.843925</td>\n",
       "      <td>0.824069</td>\n",
       "      <td>0.863659</td>\n",
       "      <td>0.857294</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tvec_nb_gs_V3</td>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>0.838332</td>\n",
       "      <td>0.822540</td>\n",
       "      <td>0.854029</td>\n",
       "      <td>0.848501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_name model vectorizer  train_score  test_score    recall  \\\n",
       "16  tvec_lr_gs_V5    lr       tvec     0.985637    0.845450  0.824579   \n",
       "13  tvec_lr_gs_V2    lr       tvec     0.996568    0.843925  0.822030   \n",
       "14  tvec_lr_gs_V3    lr       tvec     0.995933    0.843925  0.824069   \n",
       "15  tvec_lr_gs_V4    lr       tvec     0.995234    0.843925  0.824069   \n",
       "11  tvec_nb_gs_V3    nb       tvec     0.919415    0.838332  0.822540   \n",
       "\n",
       "    true_neg_rate  precision  is_tuned  \n",
       "16       0.866194   0.859649      True  \n",
       "13       0.865687   0.858817      True  \n",
       "14       0.863659   0.857294      True  \n",
       "15       0.863659   0.857294      True  \n",
       "11       0.854029   0.848501      True  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scoresV2 = pd.DataFrame(model_eval)\n",
    "model_scoresV2[model_scoresV2['model_name'].str.contains('V')]\\\n",
    ".sort_values(by=['precision', 'test_score'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d43df",
   "metadata": {},
   "source": [
    "Based on the above model, it seems that the model that performs the best is the following model:\n",
    "`LogisticRegression` with `TfidfVectorizer` with the following parameters:<br>\n",
    "\n",
    "**LogisticRegression**\n",
    "- Penalty Type: `l2`\n",
    "- Inverse Regularization Strength of `9.9` (`C`)\n",
    "\n",
    "**TfidfVectorizer**\n",
    "- `max_df` of `0.4`\n",
    "- `min_df` of `2`\n",
    "- `ngram_range` of `(1, 2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce083294",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5bd87",
   "metadata": {},
   "source": [
    "Now we will take a look at some error analysis based on our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "4b485cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe with coefs to obtain top words in our model\n",
    "coefs = pd.DataFrame(tvec_lr_gs_V5.best_estimator_.steps[1][1].coef_.T, columns=['coef'])\n",
    "coefs['ngram'] = tvec_lr_gs_V5.best_estimator_.steps[0][1].get_feature_names_out()\n",
    "\n",
    "# obtaining top words for 'r/keto' and 'r/zerocarb'\n",
    "top_keto_coefs = coefs.sort_values('coef', ascending=True).head(20)\n",
    "top_zerocarb_coefs = coefs.sort_values('coef', ascending=True).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "b75a8ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating chart of top 20 words\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data=top_keto_coefs, x=-top_keto_coefs['coef'], y='ngram', palette='Blues_r')\n",
    "plt.ylabel('')\n",
    "plt.title('Top 20 Ngrams Correlated with r/keto', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce94639",
   "metadata": {},
   "source": [
    "From the above two charts, we can see that the top words associated with our best model for `r/keto` mentions very few food items, and more of diet terminologies, e.g. 'Macros', 'goal', 'weight'. Surprisingly, it seems that covid was mentioned many times, which might be because of concerns with whether the Keto diet will interfere with covid immunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "14882654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating chart of top 20 words\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data=top_zerocarb_coefs, x=top_zerocarb_coefs['coef'], y='ngram', palette='Reds_r')\n",
    "plt.ylabel('')\n",
    "plt.title('Top 20 Ngrams Correlated with r/zerocarb', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc473f26",
   "metadata": {},
   "source": [
    "From the above chart, we can see that the top words associated with our best model for `r/keto` mentions no diet terminologies, and is mainly made up of words for meat items, e.g. 'steaks', 'lamb', 'pork'. Surprisingly, there is a word called `woe`, mentioned many times. Upon some research, we found out that `woe` is actually referring to 'way of eating' and it is commonly used among those individuals who follow a 'carnivore' diet. As such, we will remove this word, and rerun our baseline model, and our latest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ad539",
   "metadata": {},
   "source": [
    "# Rerun Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "943036b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 'woe' to stop words\n",
    "custom_stop_words += ['woe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c7b03eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136756481952212"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating pipeline for baseline model\n",
    "pipe_baseline = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words=custom_stop_words)),\n",
    "    ('nb', MultinomialNB())]\n",
    ")\n",
    "\n",
    "pipe_baseline.fit(X_train, y_train)\n",
    "\n",
    "pipe_baseline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "b35d9d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1747\n",
      "False Positives: 226\n",
      "False Negatives: 507\n",
      "True Positives: 1454\n"
     ]
    }
   ],
   "source": [
    "bm_predictions = pipe_baseline.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, bm_predictions).ravel()\n",
    "\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "print(f'True Positives: {tp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "1a874e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136756481952212"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8654761904761905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(accuracy_score(y_test, bm_predictions))\n",
    "display(precision_score(y_test, bm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f29e9",
   "metadata": {},
   "source": [
    "Our initial baseline score was **82.7%**, now our baseline score is **81.3%**. In the interest of time we will attempt to retune our `LogisticRegression` model, with `TfidfVectorizer` and attempt to get a better `accuracy` and `precision` score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c110c6",
   "metadata": {},
   "source": [
    "### Retune of LogReg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "462b9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_V6 = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2'],\n",
    "\n",
    "     # Trying different C of: 10, 1, 0.1 (C = 1/alpha)\n",
    "    'lr__C':[5, 6, 7, 8, 9, 10, 11, 12]\n",
    "}\n",
    "\n",
    "tvec_lr_params_V6 = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[2, 3, 4],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.2, 0.25, 0.3, 0.35],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "81fa6966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 6,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_lr_gs_V6',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9897044804575786,\n",
       " 'test_score': 0.8403660396542959,\n",
       " 'recall': 0.818969913309536,\n",
       " 'true_neg_rate': 0.8616320324379118,\n",
       " 'precision': 0.854709952102182,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1700\n",
      "False Positives: 273\n",
      "False Negatives: 355\n",
      "True Positives: 1606\n"
     ]
    }
   ],
   "source": [
    "tvec_lr_gs_V6 = get_model_scores_V2('tvec_lr_gs_V6', \n",
    "                              'tvec', \n",
    "                              'lr', \n",
    "                              vec_params=tvec_lr_params_V6, \n",
    "                              mod_params=lr_params_V6, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f2ab4",
   "metadata": {},
   "source": [
    "We can see that our `LogisticRegression` model, with `TfidfVectorizer`, is performing better than our baseline model, with accuracy at **84%** better by **1.3%**. Our `precision` score has deproved slightly by **1%**. Let's see if we can tune this more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "eb9734cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_V7 = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2'],\n",
    "\n",
    "     # Trying different C of: 10, 1, 0.1 (C = 1/alpha)\n",
    "    'lr__C':[5.5, 6, 6.5]\n",
    "}\n",
    "\n",
    "tvec_lr_params_V7 = {\n",
    "    # Setting a limit of n-number of features included\n",
    "    'tvec__max_features': [None],\n",
    "    \n",
    "    # Setting a minimum number of times the \n",
    "    # word/token has to appear in n-documents\n",
    "    'tvec__min_df':[1.5, 2, 2.5],\n",
    "    \n",
    "    # Setting an upper threshold/max percentage \n",
    "    # of n% of documents from corpus\n",
    "    'tvec__max_df': [0.3,],\n",
    "    \n",
    "    # Testing with ngrams\n",
    "    'tvec__ngram_range':[(1, 1), (1, 2), (1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "9185b863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "90 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2077, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1313, in fit_transform\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1259, in _validate_params\n",
      "    check_scalar(self.min_df, \"min_df\", numbers.Real, min_val=0.0, max_val=1.0)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1329, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_df == 1.5, must be <= 1.0.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2077, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1313, in fit_transform\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1259, in _validate_params\n",
      "    check_scalar(self.min_df, \"min_df\", numbers.Real, min_val=0.0, max_val=1.0)\n",
      "  File \"C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1329, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_df == 2.5, must be <= 1.0.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.83219368 0.84689765 0.84801291\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83154669 0.84713353 0.84836478        nan        nan        nan\n",
      "        nan        nan        nan 0.83094213 0.84740461 0.84801815\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.8305688  0.83972037 0.83940261\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.82986972 0.84022879 0.83972037        nan        nan        nan\n",
      "        nan        nan        nan 0.82929774 0.84022879 0.83952971\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 6,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 2,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'tvec_lr_gs_V7',\n",
       " 'model': 'lr',\n",
       " 'vectorizer': 'tvec',\n",
       " 'train_score': 0.9897044804575786,\n",
       " 'test_score': 0.8403660396542959,\n",
       " 'recall': 0.818969913309536,\n",
       " 'true_neg_rate': 0.8616320324379118,\n",
       " 'precision': 0.854709952102182,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1700\n",
      "False Positives: 273\n",
      "False Negatives: 355\n",
      "True Positives: 1606\n"
     ]
    }
   ],
   "source": [
    "tvec_lr_gs_V7 = get_model_scores_V2('tvec_lr_gs_V7', \n",
    "                              'tvec', \n",
    "                              'lr', \n",
    "                              vec_params=tvec_lr_params_V7, \n",
    "                              mod_params=lr_params_V7, \n",
    "                              grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b5fd5",
   "metadata": {},
   "source": [
    "We believe that we have pushed this model as far as it can go in terms of balance between `accuracy` and `precision`.\n",
    "In the interest of time, we will stick to `LogisticRegression` with `TfidfVectorizer` model V6, or model V7. Let's review the results between the different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54979b10",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "cf99e8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>test_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>is_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tvec_lr_gs_V6</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.840366</td>\n",
       "      <td>0.85471</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tvec_lr_gs_V7</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.840366</td>\n",
       "      <td>0.85471</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_name model vectorizer  test_score  precision  is_tuned\n",
       "17  tvec_lr_gs_V6    lr       tvec    0.840366    0.85471      True\n",
       "18  tvec_lr_gs_V7    lr       tvec    0.840366    0.85471      True"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scoresV2 = pd.DataFrame(model_eval)\n",
    "model_scoresV2.drop(columns=['train_score', 'recall', 'true_neg_rate'])\\\n",
    ".tail(2).sort_values(by=['precision', 'test_score'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "09a248d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>test_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>is_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tvec_lr_gs_V6</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.840366</td>\n",
       "      <td>0.85471</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tvec_lr_gs_V7</td>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.840366</td>\n",
       "      <td>0.85471</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>baseline_model</td>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.813670</td>\n",
       "      <td>0.86547</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_name model vectorizer  test_score  precision is_tuned\n",
       "17   tvec_lr_gs_V6    lr       tvec    0.840366    0.85471     True\n",
       "18   tvec_lr_gs_V7    lr       tvec    0.840366    0.85471     True\n",
       "19  baseline_model    nb       tvec    0.813670    0.86547    False"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scoresV2.loc[[17, 18, 19], ['model_name','model','vectorizer','test_score','precision','is_tuned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "95a80539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our custom stop words with 'woe'\n",
    "custom_stop_words = pd.DataFrame(custom_stop_words, columns=['words'])\n",
    "custom_stop_words.to_csv('datasets/custom_stop_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25a9c1",
   "metadata": {},
   "source": [
    "Based on the above model, it seems that the model that performs the best is the following model:\n",
    "`LogisticRegression` with `TfidfVectorizer` with the following parameters:<br>\n",
    "\n",
    "**LogisticRegression**\n",
    "- Penalty Type: `l2`\n",
    "- Inverse Regularization Strength of `6` (`C`)\n",
    "\n",
    "**TfidfVectorizer**\n",
    "- `max_features`: None\n",
    "- `max_df` of `0.3`\n",
    "- `min_df` of `2`\n",
    "- `ngram_range` of `(1, 2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4653ae2",
   "metadata": {},
   "source": [
    "### Top Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9333679e",
   "metadata": {},
   "source": [
    "Now we will take a look at which were the top words our model used as a predictor of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "d799775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(tvec_lr_gs_V6.best_estimator_.steps[1][1].coef_.T, columns=['coef'])\n",
    "coefs['ngram'] = tvec_lr_gs_V6.best_estimator_.steps[0][1].get_feature_names_out()\n",
    "top_keto_coefs = coefs.sort_values('coef', ascending=True).head(20)\n",
    "top_zerocarb_coefs = coefs.sort_values('coef', ascending=True).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "21d24d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data=top_keto_coefs, x=-top_keto_coefs['coef'], y='ngram', palette='Blues_r')\n",
    "# plt.xticks(np.arange(0, 6, step=1))\n",
    "plt.ylabel('')\n",
    "plt.title('Top 20 Ngrams Correlated with r/keto', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0340aa",
   "metadata": {},
   "source": [
    "From the above charts, we can see that the top words associated with our best model for `r/keto` mentions very few food items, and more of diet terminologies, e.g. 'Macros', 'goal', 'weight'. Surprisingly, it seems that covid was mentioned many times, which might be because of concerns with whether the Keto diet will interfere with covid immunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "4a7be48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAJiCAYAAABQL2/6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABHAUlEQVR4nO3deZwkdX3/8debc7kEAUVQcREV5D4W4wooV/CIikY8MYIaETWiMcRovPBnjDEm3ucaORSiRtSIJyjKIYKyCwsLcqiwikJE5EZuPr8/qkaapmd2dnd2uqf29Xw85tHdVd+q+lQfM+/5fquqU1VIkiSpe1YZdgGSJElaMQx6kiRJHWXQkyRJ6iiDniRJUkcZ9CRJkjrKoCdJktRRBj1JGoIkRyapJHsNu5bJSjK7rfmYadzm4iSLl3KZGffcrux8zVYcg54mpf0ALs3PIUOoMUmeluRjSRYmuT7J7UkuTfLhJJtMsOyGbZvFSe5IclWSo5I8YilrOLXd/3uSbD9Om2PaNvst7T6uzJI8Msm/JVnQvrZ3JbkmyQ+SvCHJ+sOucRh63k+zh13LdElyyLB+z0wkyerte/PEYdcijVlt2AVoxnj3gGlvBNYHPgLc0Ddv4YotZ6A1ge8CdwKnAz8AVgX2Ad4AvCjJnlX1i96FkmwE/AR4HPBD4EvA1sDLgb9KMreqLl/KWlYBPgA8bdl3R2OS/C3wcZrX+Hzgi8D1wEbAHsCHgXcAGw+pRK04+w67gKWwN7AB8PUh1yH9mUFPk1JVR/ZPa/+bXh/4cFUtnuaSBrkHeDvwyaq6fmxiklWATwKvBj4IPKtvuX+lCXkfqqo39Sx3OE2I/SRLH9h+CTw1yV9W1feXdkd0nyQvAT5LE+yeV1XfHtBmd+AT012bVryq+tWwa1gKz6X5PfTNYRcijXHoVitEkhckOT3JjUluS7IoyVuTrDmg7eL2Z/0kH0/yu3bI9edJDk+SyWyzqu6qqvf2hrx2+r3A/2sf7tW37XWAvwFuBd7Vt8qPA4tpAtujJ1NDj38GCvhAGzQnJclTk5yZ5NYk1yX53yRbDxqe6z1eKsnjkny5Hcq8d+w4lyS7JvlIkvPb9d2e5BdJ/jPJgwds/89DYkn+MskZSW5J8ockRyfZoG23c5JvtcNUtyQ5cdDQYZJHJ5mX5Jft++C69r3w6bYndUnPx3rAx9qHLxoU8gCq6kzgLwYsv2+S7/Xs+2Xt8O8Dhnl7ht3XSPLONEP+d6Q9Hm1J89s2j2jfw5e38/7YPje7LWlfe9bxnCTHtbXe2j6/C9rPwip9bQs4uH14Re47dGJxX7sNk7wvycXt63BjklOS7D9ODesl+WCS37bP2yVJ3sRS/M1IslVby/F907foqXPPvnn/3k7fp2fa/Y7RS3IqcHT78Ojc/5CR2QPqODDJz5L8qX0ffCnJw5diP3o/E09r3wc3ts99b7sABwBnVNW17bQlHeJyZN86Jv06TaauNL9T39e+V29P83k9KRMcNpJk/yTfTPO75I4kVyb5Ru8y7Wfg75J8J8mv23bXpTmM4unjrHfs9/yD2vfW4jSHXxw5oO3BSc5rn4Nr0hxG87DxatbE7NHTlEvyr8BbgWuB/wZuAZ5O03M21st1V99ia9AMtW5AM3S6BvA8mh61rYDXLWdZd7a3d/dNnwusBZxcVTf3zqiqe5OcDBxKMySzNMO35wHH0YTIg7nvD9O4kryQ5vm6A/gf4GrgScBZNMOV49kS+ClwGXB8uz83tfNeRdPLcBr3DWXvArwJeHqSv+jf79azgWcC3wI+3dZxCLBFkrcApwBnAJ8DtqfpJd0yyfZtsCbJpsA5wIOA7wBfBWYBW7TPy8eBPy7haTkQ2BA4u6pOnqhhVd3R+zjJq4FP0YT4rwDX0AT9fwKelWT3qrphwKq+CuxGcxjA/7bLLXF+kl2Ak9t6TwK+RjOU/Bzgx0meW1XfWcL+AvwbcC/Na/o7ml7zfWg+C7vRPHdj3t2uf0fufwjFn/cryaOAU4HZNK/Z94B1aF7f7yV5dVV9tqf9mjSv724077vjaT6X7wCeMon6AaiqS5P8rq29175998/oebwPcDvNoRTjOYZm/w4AvsH9DxO5oa/ta2neyyfSfAb+AnghsGOSnfrfM0twIE3P/ndpPhOz++bPBTYF3tczbdAhL9C8ho8G/jQ2YWlfpyXVleafsjOBbWg+hx+meT++ADg5yWuq6jO9K0rybuCdNL+z/xe4EtiM5vP/UprfIdC8xz9C8zp9H/hDu+/PAr6T5FVV9V8Dal2D5vCYDWk+KzcBV/S1+Xtgf+DL7XOwB81hNHu1v6/+MGC9mkhV+ePPMv3Q9HYVMLtn2tx22m+Ah/VMX41mOKOAfx5nPT8G1uyZviHwq3bek5ez1n9q1/PFvumva6d/bJzljmjnv3+S2zm1bf8Y4JHAbcBvgbV72hzTttmvZ9p6NEOTdwA79q3z39r2/c/17J7p/zpOPY8CVh0w/ZXtcv/UN/2QdvrdwFN6pq9C8wu9gOuAg/qW+1w774Ceaa9vp71hwPbXAdaaxPM5tt5/WcrX+1Htc3kTsHXfvE+265w3zmt3AbDxBK/tA+a37+9f0oSUp/TN24wmsF3d9/4+sl3fXn3ttxyw7VWAY9v2f9E3b+z9NLt/uZ6676XpEe2dvgFNSLoN2KRn+lhv9FeBVXqmb9G+9gUcM8nX4fNt+217pn2RJhicR9P7NTb9wTTDnqf0rWMxsHic9+kh42x37Lm9Cdi+b95/t/NeMMl9GNvWvcDTJmj3gbbdI5ewvpe37c4CZi3H6zRhXcBn2vmfAdIz/bHAjTSfj97fJ/u37S8HHj5gfY/oub9m7+Oe6esDF7bvk7X65i1u1/8DYJ0JXrM7gZ375n2onfe5ybxm/tz/x6FbTbVXtLf/UlX/Nzaxqu4G/oHml9LfjrPsW6vnP+yqug54T/vw5ctaUJphs3cBN9Mcw9drbAjvxnEWH5u+wdJut6qupPkv+uE0PWgTOaDdxvFV1d979y88sKei1+8Zp+egqn5dVfcMmHUUzR/Bp46zzi9W1Wk967kX+EL78MKqOr6v/efb250GrOu2AXXdWlUPmD7Apu3tbyfRttdLaXoPPl5Vl/TNexvNe+FvMuBQAuAd1Q69jWPQ/L+i6Vn9WO/zBlBVVwH/DjyMSZxYUAOOSWuf/4+0D8d7zR4gyY40vXBfraov9a3zBprPxSya3vMxL6f5nL653e5Y+yuAj052261T2tve/d6bplfnB8BfJFm3Z/oqPctMhY9W1aK+aWO9Yk9YynV9o6q+N8H85wLz28/9QEn2pQlelwPPrqrb2+nL8jqNW1eS1Wk+A7fQ/F7983BuNSejfZTm8/GynsVe397+Q1X9rn8jVfXbnvt39D7umX4jze+WB9P0CA/yD1V16zjzAL5QVef1TTuS5nfxS8b5zGoCDt1qqu3S3v6wf0ZVXZbktzTDfxvU/YfN7mbwcM2p7e3Oy1JMksfR9CSuTvOf8tIe2D12fGBN2Gp876PpPXtzks9W1e/HaTe2fz/un1FVtyRZSN/xhT3Or3GGoNpf+K8GXkQzhLM+9z/OarxjleYPmHZVe7tgwLyxPwy9l6M5kWa4/hNJnkoznHkm8PPePzxLsKzP/0Tvw+uTnAc8mebs6v5g/bMlrHvQ/Lnt7aMGHXNE04sC8HiaYexxpTl28R+BZ9AM763T12TSx5f11LX+OHU9pKeusWMiHwNcOc5n5VQeeCzrRHqD3keTbAds0k6/kqbHfE+aYcexId4HvGbLYdD7eCyIPeAY1SUY932RZAeaoP+2CdpsQ9NLegvwjLr/EORSvU6TqGtrYG3gzPYf5n4/pPmnt/f36hNpPmcThdk/S7Itzfv0yTT/kM3qazLofXo7TY/4RE7rn1BVN7a/A59C8xwsnEyNahj0NNXGesiuHmf+1cDmbbsbeqZfO07P01iv4PoD5k0oyWOBH9EMAb+oqgZd22qsx2689T+or91Sqaqb2uNePk7zX+lrxmk6tv3xguB40+G+52iQL9P0NFxOczzT/9EM2UBzeZzx/jsetL93T2Le6mMTqurXSZ5As99PA/66nXVlkv+oqsn0Do2Fy6W6niGTex/C4J7aiZ7P8eaPnVjy/CUsu+5EM9vjqs6hGSb9GU1P6XU0z+8GNJcJWpoejbG6/rL9WVJdS3ofLum5uZ+q+m2SX9AcX7Uq9/XsndKu66522nfb25sYHM6W1Q0Dpo29V1ddynVNtO/PbW+/NmhmeyLBd2iOn92/qi7ta7K0r9OS6lqW9/8GwPWT6WlP8kSasLgazWt5Is1rdy9Nr/4BDH6fXjOJf/KW9N5b6r8FKzuDnqbaWAh4GM3xdf027Ws3ZuMkqw4Iew8bp/2Ekjye5hfQRsDzq+ob4zQd+4X7uHHmj/XEXLY02+/zGeBw4FVJxgs3YydPjHdR53Ev9sw4vV1J5tD8AfoBTQ/CXT3zVgHePFHRU6GqLgZemGQ1mhMG9qMZIvpIklur6nNLWMWPaQ4H2JfmZIDJ6n0fXjRg/njvQ5b0h2ic+WPrOWCcfygm629pQt67q++SRknm0gS9pTFW1xsmGazH2o/3fluWMx9/SNOrvBvN6/ibsd7CJD8D9mtP3Nka+FZ7mMcomuh98VzgkgGHCZBkbZpRhUcBL+0f2m8t7eu0pLp63/+DDHr/3wBslGStSYS9t9OE1r2r6tTeGUneShP0JltrvyW995bpn+6VmcfoaaqNHVuxV/+MJI+h6Zm5oh54tuNqNGd29RtbT/8xG+NK840Up9L05D1vgpAHcDbNMWS7t8NWvetZheYAZWh6BpdJ+4frn2h6EP59nGZj+7dH/4z2GKadlmHTj2lvT6wHnuX8BJpf1NOiqu6uqgVV9X7gxe3k50xi0RNoerTmTnRJCPjz2aJjJnofbkDzfN4OXDyJGibj7PZ2zwlbLdnYa/bVAfOeMs4yY/8cDeqhWqq6qjkD+5fAw5NsOaDJXpNZT5+x4dun0gzz/aBv3g40hxb0tl2SifZ5WiXZguafmK8PmLcKzckfc4B3Dji2dcxUvX/GXEpzRu9OGXAZJZrjIQHO7ashTO6aoY8BrusPea3x3qeT9YDl01wOaSem9jO70jDoaaod1d6+PcnYcSW0wzb/QfOeG68X5329f6yTbMh9J08cPZmNJ9mJJpStR9O78q2J2lfVLTQnGaxDM8TY6+9ozmw9qZb+mzH6t/O/NJdMeCaw+4Am36D5T/Wg9sDsXm9nGU4GoTnLDR547cCHMg0XF07yhAz+2rmxaX8aMO9+2uBxePvwy+2xfoO29USasxjHHEczLPj69h+MXu+hGZI/brxjG5fBN2h6sF+X5Bnj1Di37d2ZyOL2dq++ZXemuWTRIGOXqNm8f0ZVzad53/11klf0z2/XvX37nhhzNM3n9P3puW5fG2gO719+En5E05PzWppht94w90OacPGWnseTMe4+D8HYIQkPCHo0F2g/ADi2qt4zYD6wzK/TuKrqTprL4qzLfdcQHVvPljSv413cd4IV3He9yv/MgOsM9k1bDGzYHpvY2+aVLMXJQuP4m/b93utImvfOF6fwM7vScOhWU6qqfpLk32mGBS9McgLNdcyeDmxHMxT3gQGLXk1zTMeFab4ncnWa60NtSvNNF6cvadvtf66n0PTknULTCzR3QNMP9/Uo/jPNH9Y3tUHxZzQH/B5Ac4205b2G35gjaP5r7g8eY8fyvZYmoPwkSe919HakOUD5KTTHwEzWOTQnP/x1kp/QPPeb0LwWl3Lf8W8ryktogs9pNL1E19McsP4smuMEPzyZlVTV8UnWojnO8XvtQdk/4b6vQJtL8xxd27PM4iRvpAm057bP5x9onsO5wCU0vaxToqruSvLXNCecfLt9vhfShNlH0gxbPprm/TxRwP08zQHuH06yN/ALmsMHnklz/NcLByxzSrvMZ9vP2y3ADVX18Xb+S2gC1OfSfNvLT2mG6R5B05u2Hc1zMna9wP+k6W19Hs1zdxLNH9kX0ny14LMn+bQAUFXXJrmA5jWC+4e5s2iej4fSvD79Z8iOZ2y5N7b/EI4d1/Wx9szP6fRc4LdVdU7vxPb41DfQ9EL9bpyTLE7t6RVb2tdpSd5C00P4d+2VB37EfdfRWw/4u/ZMagCq6uQk76E5ROLiJP9Lc+LKJjQjDWfTXNIFms/uU2muD/k/NP+kzmnbnUDzu3tZfRc4s+d34B7tz2Lu+4dAS6P/eiv++DPZHwZcR69n3otogsXNNL/oLqI5I23WOOtZTPPH5BM0Z3DeQdNFfzg914BaQj2zue+6chP9DKp37AKgv6a5jtPVNL2TD7hW1BJqOLXdxmPGmf/Fnjr2GzD/6TQh5k80QeYbtMcutctsMGB/j5mgng1prhu3uH0dfkVzJuzaLOX1yWjCcAFHTvDcH9Mz7S9oLlh8Ps3w6200ge9oYLtleL89Eng/zXDTDTQ9En+g+QP2RuBBA5bZn+bCrNe376lf0gyfbzCg7am0h+BN9NouocaH0lz38ML2NbyFJqydQHO5i9V62h7J4OvobUNzcPs1NP8kLaA5dm/c15vm8j0Xt/tYA17X9Wj+oVnQ1nQbzYVqv01zQfB1+to/iKY36nft++YSmssjPXpJ77lxnpf/bJe7aMC8k9p5Xx5n2Qe8T9vpT6MJfLfQ99ke77md7OdmKT4Tm9AMI390gs/LRD9H9i0z6ddporp62mxA85n5RfveuIHmepj7T7DMM2jOvL2uXeZKmt7KffraPZMm/N3crvdkmqH5gXWN9zoO+jy061jY7v8faH5nbLq0vzP8aX7SPsHS0KT9eqOqmj3cSkZTO+x9Oc3Fdv0aIGlEJDmU5mSrfapqmY/jlVYkj9GTRkSSDfqP4UoSmmP0NmecSzdIGprn0hwvuMRDS6RhsUdPQ2ePXiPJ02iue3cyzTDHujQXMd2JZvhkTlVN9vgcSZI8GUMaIZfSHIu3O81xMqvRfPXXR2m+y9aQJ0laKvboSZIkdZTH6EmSJHWUQ7cDbLzxxjV79uxhlyFJkrRECxYsuLaqHjJonkFvgNmzZzN//lR+r7YkSdKKkeTX481z6FaSJKmjPBljgE1WX6Ne/GCvSyt12Yev+c2wS5CkKZFkQVXNGTTPHj1JkqSOMuhJkiR1lEFPkiSpowx6kiRJHWXQkyRJ6iiDniRJUkfNqKCX5DlJtul5/P+S7DfMmiRJkkbVjAp6wHOAPwe9qnpnVf1geOVIkiSNrgmDXpI3Jzm8vf+hJD9s7++b5Lj2/qeSzE9yUZJ398z/es96/jLJ1wasf9ckpyVZkOSkJJu201+V5Jwk5yf5apK1kzwJeDbwgSQLk2yZ5JgkB7bLLE7y7iTnJlmUZOt2+kOSfL+d/pkkv06y8VQ8eZIkSaNsST16pwN7tvfnAOsmWR3YAzijnf629mrMOwBPSbID8EPg8UnGvmD35cDRvStu1/Mx4MCq2hU4CnhvO/trVbVbVe0IXAy8sqp+ApwI/GNV7VRVvxpQ77VVtQvwKeCIdtq7gB+2078ObL6EfZYkSeqEJQW9BcCuSdYD7gDOogl8e3Jf0HtBknOB84BtgW2q+V61LwAvTbIBMBf4bt+6twK2A76fZCHwduAR7bztkpyRZBFwULveyRjrNVwAzG7v7wF8CaCqvgdcP2jBJIe2PZPzb7v33kluTpIkaXStNtHMqroryWKaHrmfABcAewNbAhcn2YKm52y3qro+yTHArHbxo4FvArcDX6mqu/tWH+Ciqpo7YNPHAM+pqvOTHALsNcn9uaO9vadn3zKZBatqHjAPmu+6neT2JEmSRtZkTsY4nSbMnU7Ti3cYsLDttXsQcCtwY5JNgKePLVRVVwFX0fTUHTNgvZcCD0kyF5qh3CRjPXfrAVe3w7sH9SxzcztvafwYeEG7jf2BBy/l8pIkSTPSZILeGcCmwFlV9XuaHrozAKrqfJoh24tojrE7s2/Z44Erq+rn/SutqjuBA4H3JzkfWAg8qZ39DuCnwPeBS3oW+xLwj0nOS7LlZHYQeDewfzu8/HTgaprAKEmS1GlpOuZW0MqTjwPnVdXnVthGllzDmsA9VXV323v4qaraaaJlNll9jXrxgx82LfVJGo4PX/ObYZcgSVMiyYL2xNgHmPAYveXdKM2w7j+sqG1M0ubA/yRZBbgTeNWQ65EkSZoWKyzotZdMGbqq+gWw87DrkCRJmm4z7ZsxJEmSNEkGPUmSpI4y6EmSJHWUQU+SJKmjVtjJGDPZI3fcgQ/Pnz/sMiRJkpaLPXqSJEkdZdCTJEnqKIOeJElSRxn0JEmSOsqTMQa4+oJFvHfzLYddhqRp8rbf/GrYJUjSCmGPniRJUkcZ9CRJkjrKoCdJktRRBj1JkqSOMuhJkiR1lEFPkiSpo2ZM0Etyy7BrkCRJmklmTNCTJEnS0pmRQS/JPyY5J8kFSd7dM/1/kyxIclGSQ3um35LkvUnOT3J2kk2GU7kkSdL0mXFBL8n+wGOBJwA7AbsmeXI7+xVVtSswBzg8yUbt9HWAs6tqR+B04FXTW7UkSdL0m3FBD9i//TkPOBfYmib4QRPuzgfOBh7ZM/1O4Fvt/QXA7P6VJjk0yfwk82+9994VV70kSdI0mYnfdRvgfVX1mftNTPYC9gPmVtWfkpwKzGpn31VV1d6/hwH7XVXzgHkAD19jzeqfL0mSNNPMxB69k4BXJFkXIMnDkzwUWB+4vg15WwNPHGaRkiRJwzbjevSq6uQkjwfOSgJwC/BS4HvAYUkuAC6lGb6VJElaaeW+EU2Nefgaa9ZrH/aIYZchaZq87Te/GnYJkrTMkiyoqjmD5s3EoVtJkiRNgkFPkiSpowx6kiRJHWXQkyRJ6iiDniRJUkcZ9CRJkjpqxl1HbzpsusP2vG3+/GGXIUmStFzs0ZMkSeoog54kSVJHGfQkSZI6yqAnSZLUUZ6MMcAfLryITz/m8cMuQ9I0OeyXFw+7BElaIezRkyRJ6iiDniRJUkcZ9CRJkjrKoCdJktRRBj1JkqSOMuhJkiR11IwKeknemGTtnsffSbLBEEuSJEkaWTMq6AFvBP4c9KrqGVV1w9CqkSRJGmFDD3pJXprkZ0kWJvlMklWTfCrJ/CQXJXl32+5wYDPgR0l+1E5bnGTjJLOTXJzks+0yJydZq22zW5ILkpyV5ANJLhze3kqSJE2foQa9JI8HXgjsXlU7AfcABwFvq6o5wA7AU5LsUFUfBa4C9q6qvQes7rHAJ6pqW+AG4Hnt9KOBw6pqbrt+SZKklcKwvwJtX2BX4JwkAGsB1wAvSHIoTX2bAtsAFyxhXVdU1cL2/gJgdnv83npV9ZN2+n8Dzxy0cLu9QwE2XG3YT4skSdLyG3aiCXBsVb31zxOSLYDvA7tV1fVJjgFmTWJdd/Tcv4cmNGayhVTVPGAewKNmrVWTXU6SJGlUDfsYvVOAA5M8FCDJhsDmwK3AjUk2AZ7e0/5mYL3JrryqrgduTvLEdtKLpqRqSZKkGWCoPXpV9fMkbwdOTrIKcBfwOuA84CLgcuDMnkXmAd9NcvU4x+kN8krgs0luBU4Fbpyq+iVJkkZZqro9Splk3aq6pb3/FmDTqnrDRMs8atZa9dZHzJ6O8iSNgMN+efGwS5CkZZZkQXsS6wMM+xi96fBXSd5Ks6+/Bg4ZbjmSJEnTo/NBr6q+DHx52HVIkiRNt2GfjCFJkqQVxKAnSZLUUQY9SZKkjjLoSZIkdVTnT8ZYFg/ZblsOmz9/2GVIkiQtF3v0JEmSOsqgJ0mS1FEGPUmSpI4y6EmSJHWUJ2MMcN1FF3H847cfdhmShuSgixcNuwRJmhL26EmSJHWUQU+SJKmjDHqSJEkdZdCTJEnqKIOeJElSRxn0JEmSOqrzQS/JMUkObO+/Mcnaw65JkiRpOnQ+6PV5I2DQkyRJK4UZecHkJOsA/wM8AlgVeA+wFfAsYC3gJ8Crq6p6ljkc2Az4UZJrq2rvaS9ckiRpGs3UHr2nAVdV1Y5VtR3wPeDjVbVb+3gt4Jm9C1TVR4GrgL0NeZIkaWUwU4PeImC/JO9PsmdV3QjsneSnSRYB+wDbLs0KkxyaZH6S+Tfdfc+KqFmSJGlazcih26q6LMmuwDOA9yU5GXgdMKeqrkxyJDBrKdc5D5gH8Oi11qolNJckSRp5M7JHL8lmwJ+q6jjgP4Bd2lnXJlkXOHCcRW8G1puGEiVJkoZuRvboAdsDH0hyL3AX8BrgOTRDuouBc8ZZbh7w3SRXe5yeJEnquvScmKrWo9daq94z+zHDLkPSkBx08aJhlyBJk5ZkQVXNGTRvRg7dSpIkackMepIkSR1l0JMkSeoog54kSVJHGfQkSZI6yqAnSZLUUTP1Onor1IbbbstB8+cPuwxJkqTlYo+eJElSRxn0JEmSOsqgJ0mS1FEGPUmSpI4y6EmSJHWUZ90OcMPPf86JO+wy7DIkDdmzLzh32CVI0nKxR0+SJKmjDHqSJEkdZdCTJEnqKIOeJElSRxn0JEmSOsqgJ0mS1FEzLuglOTXJnGVcdq8kT5rqmiRJkkbRjAt6y2kvwKAnSZJWCiMb9JLMTnJJkmOTXJDkhCRr97X5VJL5SS5K8u6e6YuTvDvJuUkWJdk6yWzgMODvkyxMsuc075IkSdK0Gtmg19oKmFdVOwA3Aa/tm/+2qpoD7AA8JckOPfOurapdgE8BR1TVYuDTwIeqaqeqOmPFly9JkjQ8ox70rqyqM9v7xwF79M1/QZJzgfOAbYFteuZ9rb1dAMxe0oaSHNr2Ds6/6e67l69qSZKkETDqQa/Ge5xkC+AIYN+2x+/bwKyetne0t/cwie/0rap5VTWnquY8aDW/AliSJM18ox70Nk8yt73/YuDHPfMeBNwK3JhkE+Dpk1jfzcB6U1uiJEnSaBr1oHcxcHCSC4ANaY63A6CqzqcZsr0IOAo4c+Aa7u+bwHM9GUOSJK0MRn2M8t6qOqxv2l5jd6rqkEELVdXsnvvzx5apqstoTtyQJEnqvFHv0ZMkSdIyGtkevfZyKNsNuw5JkqSZyh49SZKkjjLoSZIkdZRBT5IkqaNG9hi9Ydpgm2149vz5wy5DkiRpudijJ0mS1FEGPUmSpI4y6EmSJHWUQU+SJKmjDHqSJEkd5Vm3A9x8ySWcOnfusMuQNAL2OuusYZcgScvMHj1JkqSOMuhJkiR1lEFPkiSpowx6kiRJHWXQkyRJ6iiDniRJUkfN6KCX5MgkRwyYvlmSE4ZRkyRJ0qjo5HX0quoq4MBh1yFJkjRM09qjl2R2kouTfDbJRUlOTrJWki2TfC/JgiRnJNk6yapJLk9jgyT3Jnlyu54zkjymXe2OSX6Y5BdJXtWznQvb+6sm+UCSc5JckOTV07nPkiRJwzKModvHAp+oqm2BG4DnAfOA11fVrsARwCer6h7gMmAbYA9gAbBnkjWBR1TVL9v17QD8FTAXeGeSzfq290rgxqraDdgNeFWSLVbkDkqSJI2CYQzdXlFVC9v7C4DZwJOAryQZa7Nme3sG8GRgC+B9wKuA04Bzetb3jaq6DbgtyY+AJwALe+bvD+yQZGwod32asHlFb1FJDgUOBdhkjTWWZ/8kSZJGwjCC3h099+8BNgFuqKqdBrQ9AzgM2Ax4J/CPwF7A6T1tqm+Z/seh6S08aaKiqmoeTc8iW627bv86JEmSZpxROOv2JuCKJM8HaI/J27Gd91Oa3r57q+p2mp66V9MEwDEHJJmVZCOaENjb2wdwEvCaJKu3639cknVW1M5IkiSNilEIegAHAa9Mcj5wEXAAQFXdAVwJnN22OwNYD1jUs+zPgG+3bd7TnnHb67+AnwPntidofIaOnm0sSZLUK1WOUvbbat116zPbbz/sMiSNgL3OOmvYJUjShJIsqKo5g+aNSo+eJEmSpphBT5IkqaMMepIkSR1l0JMkSeoog54kSVJHGfQkSZI6yuvJDbDe1lt7SQVJkjTj2aMnSZLUUQY9SZKkjjLoSZIkdZRBT5IkqaM8GWOAP112KfP3f8qwy5A0guacfNqwS5CkSbNHT5IkqaMMepIkSR1l0JMkSeoog54kSVJHGfQkSZI6yqAnSZLUUSs86CWZneTCpWi/V5InTeU6JUmSVkaj2KO3FzBh0FteSbx+oCRJ6rzpCnqrJTk2yQVJTkiydpLFSTYGSDInyalJZgOHAX+fZGGSPZNskuTrSc5vf8ZC4KpJPpvkoiQnJ1mrXdeWSb6XZEGSM5Js3U4/JskHk/wIeP807bckSdLQTFfQ2wqYV1U7ADcBrx3UqKoWA58GPlRVO1XVGcBHgdOqakdgF+CitvljgU9U1bbADcDz2unzgNdX1a7AEcAnezbxOGC/qvqHKdw3SZKkkTRdQ5hXVtWZ7f3jgMOXYtl9gJcBVNU9wI1JHgxcUVUL2zYLgNlJ1qUZ9v1KkrHl1+xZ11fadTxAkkOBQwEeNmvNQU0kSZJmlOkKejXg8d3c16M4axnWeUfP/XuAtdr13VBVO42zzK3jFlg1j6Y3kG0etF5/vZIkSTPOdA3dbp5kbnv/xcCPgcXAru205/W0vRlYr+fxKcBrAJKsmuRB422kqm4Crkjy/LZ9kuw4JXsgSZI0w0xX0LsYODjJBcCGwKeAdwMfSXIGTY/cmG8Czx07GQN4A7B3kkU0Q7TbLmFbBwGvTHI+zfF8B0ztrkiSJM0MqXKUst82D1qvPv/EXYZdhqQRNOfk04ZdgiTdT5IFVTVn0LxRvI6eJEmSpoBBT5IkqaMMepIkSR1l0JMkSeoog54kSVJHGfQkSZI6arq+GWNGWftxW3kJBUmSNOPZoydJktRRBj1JkqSOMuhJkiR1lEFPkiSpozwZY4Dbf/ULLvnrpw67DEkz2NZfO2nYJUiSPXqSJEldZdCTJEnqKIOeJElSRxn0JEmSOsqgJ0mS1FEGPUmSpI4aqaCX5I1J1l6O5U9NMmcqa5IkSZqpRiroAW8EljnoSZIk6T5DC3pJ1kny7STnJ7kwybuAzYAfJflR22b/JGclOTfJV5Ks205/Z5Jz2uXmJUnfuldJcmySf0myapJj2raLkvz99O+tJEnS9Btmj97TgKuqaseq2g74MHAVsHdV7Z1kY+DtwH5VtQswH3hTu+zHq2q3drm1gGf2rHc14Hjgsqp6O7AT8PCq2q6qtgeOnoZ9kyRJGrphBr1FwH5J3p9kz6q6sW/+E4FtgDOTLAQOBh7Vzts7yU+TLAL2AbbtWe4zwIVV9d728eXAo5N8LMnTgJsGFZPk0CTzk8y//o47p2QHJUmShmloQa+qLgN2pQl870vyzr4mAb5fVTu1P9tU1SuTzAI+CRzY9tB9FpjVs9xPaILgrHY71wM7AqcCrwP+a5x65lXVnKqa8+A115i6HZUkSRqSYR6jtxnwp6o6DvgPYBfgZmC9tsnZwO5JHtO2XzvJ47gv1F3bHrN3YN+qPwd8B/hKktXaIeBVquqrwDva7UiSJHXeakPc9vbAB5LcC9wFvAaYC3w3ydXtcXqHAF9Msma7zNur6rIkn6XpCVwMnNO/4qr6YJL1gS8A/wYcnWQs1L51Re6UJEnSqEhVDbuGkbPdg9evE/Z+4rDLkDSDbf21k4ZdgqSVRJIFVTXwOsKjdh09SZIkTRGDniRJUkcZ9CRJkjrKoCdJktRRBj1JkqSOMuhJkiR11DCvozeyZm35WC+NIEmSZjx79CRJkjrKoCdJktRRBj1JkqSOMuhJkiR1lCdjDHDH4l9x+SueO+wyJHXQo4/6+rBLkLQSsUdPkiSpowx6kiRJHWXQkyRJ6iiDniRJUkcZ9CRJkjrKoCdJktRRnQt6SQ5J8vH2/mFJXtYzfbPhVidJkjR9On0dvar6dM/DQ4ALgauGU40kSdL0mnFBL8lLgcOBNYCfAq8FXga8FbgauAy4o217JHALsBiYAxyf5DZgblXdNt21S5IkTacZNXSb5PHAC4Hdq2on4B7gpcC7gd2BvwS26V+uqk4A5gMHVdVOhjxJkrQymGk9evsCuwLnJAFYC3gScGpV/QEgyZeBxy3tipMcChwKsNk6a01VvZIkSUMzo3r0gADHtr1yO1XVVsCRQC3viqtqXlXNqao5G85ac3lXJ0mSNHQzLeidAhyY5KEASTYEzgP2SrJRktWB54+z7M3AetNTpiRJ0vDNqKHbqvp5krcDJydZBbgLeB1Nr95ZNCdjnAusOmDxY4BPezKGJElaWaRquUc9O2f7jR9c33j2XsMuQ1IHPfqorw+7BEkdk2RBVc0ZNG+mDd1KkiRpkgx6kiRJHWXQkyRJ6iiDniRJUkcZ9CRJkjrKoCdJktRRM+o6etNlzdlbegkESZI049mjJ0mS1FEGPUmSpI4y6EmSJHWUQU+SJKmjDHqSJEkd5Vm3A9x55RVc+fcHDbsMSR33yA8dP+wSJHWcPXqSJEkdZdCTJEnqKIOeJElSRxn0JEmSOsqgJ0mS1FEjG/SS3DJF6zkyyRFTsS5JkqSZZGSDniRJkpbPyAe9JOsmOSXJuUkWJTmgnT47ySVJ/ivJhUmOT7JfkjOT/CLJE3pWs2OSH7bTXzWkXZEkSZpWM+GCybcDz62qm5JsDJyd5MR23mOA5wOHAucALwH2AJ4N/DPwnLbdDsATgXWA85J8u6qumr5dkCRJmn4j36MHBPjXJBcAPwAeDmzSzruiqhZV1b3ARcApVVXAImB2zzq+UVW3VdW1wI+A3t6+ZiPJoUnmJ5l/3W23r8DdkSRJmh4zIegdBDwE2LWqdgJ+D8xq593R0+7ensf3cv/eyupbZ/9jqmpeVc2pqjkbrjWrf7YkSdKMMxOC3vrANVV1V5K9gUctwzoOSDIryUbAXjTDvJIkSZ02E47ROx74ZpL5wELgkmVYx8+AbwObA+/x+DxJkrQyGNmgV1XrtrfXAnPHabZdT/tDeu4vHptXVUeuqBolSZJG2UwYupUkSdIyMOhJkiR1lEFPkiSpowx6kiRJHWXQkyRJ6iiDniRJUkeN7OVVhmmNR27BIz90/LDLkCRJWi726EmSJHWUQU+SJKmjDHqSJEkdZdCTJEnqKIOeJElSR3nW7QB3XfVrrj7ysGGXIWklsemRnx52CZI6yh49SZKkjjLoSZIkdZRBT5IkqaMMepIkSR1l0JMkSeoog54kSVJHdTLoJZmd5CXDrkOSJGmYOhn0gNmAQU+SJK3UZtQFk5O8DDgCKOAC4B7gW1V1Qjv/lqpaF/g34PFJFgLHAicDRwNr0ITb51XVL6Z/DyRJkqbPjAl6SbYF3gbsXlXXJtkQ+OA4zd8CHFFVz2yX/Rjwkao6PskawKrTUrQkSdIQzaSh232AE6rqWoCqum4plj0L+Ock/wQ8qqpu62+Q5NAk85PM/+Ofbp+aiiVJkoZoJgW90AzZ9rqbdh+ShGZo9gGq6r+BZwO3AScl2WdAm3lVNaeq5my09qwpLVySJGkYZlLQOwV4QZKNANqh28XAru38A4DV2/s3A+uNLZjk0cDlVfVR4ERgh2mqWZIkaWhmzDF6VXVRkvcCpyW5BzgP+CfgG0l+RhMEb22bXwDcneR84BhgFvDSJHcB/wf8v+muX5IkabrNmKAHUFXH0pxF2+uJPfff2ra7C9i3r937VmBpkiRJI2cmDd1KkiRpKRj0JEmSOsqgJ0mS1FEGPUmSpI4y6EmSJHXUjDrrdrqsvtmj2PTITw+7DEmSpOVij54kSVJHGfQkSZI6yqAnSZLUUQY9SZKkjjLoSZIkdZRn3Q5w1+9/y+8/+OZhlyFJ02aTN/37sEuQtALYoydJktRRBj1JkqSOMuhJkiR1lEFPkiSpowx6kiRJHWXQkyRJ6qgZEfSS3NLebpbkhGHXI0mSNBPMiKA3pqquqqoDl3c9Sbx+oCRJ6rwZFfSSzE5yYXv/p0m27Zl3apJdk6yT5Kgk5yQ5L8kB7fxDknwlyTeBk4e0C5IkSdNmRgW9Pl8CXgCQZFNgs6paALwN+GFV7QbsDXwgyTrtMnOBg6tqn2EULEmSNJ1mctD7H+D57f0XAF9p7+8PvCXJQuBUYBaweTvv+1V13aCVJTk0yfwk86+79bYVVrQkSdJ0mbHHqlXV75L8MckOwAuBV7ezAjyvqi7tbZ/kL4BbJ1jfPGAewI6PfFitmKolSZKmz0zu0YNm+PbNwPpVtaiddhLw+iQBSLLzsIqTJEkappke9E4AXkQzjDvmPcDqwAXtiRvvGUZhkiRJwzYjhm6rat32djGwXc/039O3D1V1G/cN4/ZOPwY4ZgWWKUmSNFJmeo+eJEmSxmHQkyRJ6iiDniRJUkcZ9CRJkjrKoCdJktRRBj1JkqSOmhGXV5luq2/yCDZ5078PuwxJkqTlYo+eJElSRxn0JEmSOsqgJ0mS1FEGPUmSpI7yZIwB7r72av7w2fcMuwxJGpqHvOodwy5B0hSwR0+SJKmjDHqSJEkdZdCTJEnqKIOeJElSRxn0JEmSOsqgJ0mS1FEjEfSSbJDktZNod0t7OzvJhSu+MkmSpJlrJIIesAGwxKAnSZKkyRuVoPdvwJZJFib5UJJTkpybZFGSAyZaMMmsJEe3bc9Lsnc7/TtJdmjvn5fkne399yT52xW+R5IkSUM2Kt+M8RZgu6raKclqwNpVdVOSjYGzk5xYVTXOsq8DqKrtk2wNnJzkccDpwJ5JFgN3A7u37fcAjluROyNJkjQKRqVHr1eAf01yAfAD4OHAJhO03wP4AkBVXQL8GngccAbw5Hb+t4F1k6wNzK6qSx+w0eTQJPOTzP/jzbdO5f5IkiQNxaj06PU6CHgIsGtV3dX2yM2aoH3GmX4OMAe4HPg+sDHwKmDBoMZVNQ+YB7DT7IeP13soSZI0Y4xKj97NwHrt/fWBa9qQtzfwqCUsezpNOKQdst0cuLSq7gSuBF4AnE3Tw3dEeytJktR5IxH0quqPwJntJVN2AuYkmU8T4C5ZwuKfBFZNsgj4MnBIVd3RzjsD+H1V/am9/wgMepIkaSUxMkO3VfWSSbRZt71dDGzX3r8dOGSc9u8A3tHev4rxh3klSZI6ZyR69CRJkjT1DHqSJEkdZdCTJEnqKIOeJElSRxn0JEmSOsqgJ0mS1FEjc3mVUbLaxpvykFe9Y9hlSJIkLRd79CRJkjrKoCdJktRRBj1JkqSOMuhJkiR1lCdjDHD3dddw3Zc+OuwyJGkkbfiiw4ddgqRJskdPkiSpowx6kiRJHWXQkyRJ6iiDniRJUkcZ9CRJkjrKoCdJktRRIxv0kpyaZM4yLrtXkidNdU2SJEkzycgGveW0F2DQkyRJK7WhXzA5yWzge8BPgZ2By4CX9bX5FLAbsBZwQlW9q52+GDgWeBawOvB84HbgMOCeJC8FXg88DHgXcA9wY1U9eUXvlyRJ0rANPei1tgJeWVVnJjkKeG3f/LdV1XVJVgVOSbJDVV3Qzru2qnZJ8lrgiKr62ySfBm6pqv8ASLIIeGpV/S7JBtO0T5IkSUM1KkO3V1bVme3944A9+ua/IMm5wHnAtsA2PfO+1t4uAGaPs/4zgWOSvApYdVCDJIcmmZ9k/h9vvmUZdkGSJGm0jErQq/EeJ9kCOALYt6p2AL4NzOppe0d7ew/j9FBW1WHA24FHAguTbDSgzbyqmlNVczZab91l3hFJkqRRMSpBb/Mkc9v7LwZ+3DPvQcCtwI1JNgGePon13QysN/YgyZZV9dOqeidwLU3gkyRJ6rRRCXoXAwcnuQDYEPjU2IyqOp9myPYi4CiaYdgl+Sbw3CQLk+wJfCDJoiQXAqcD50/1DkiSJI2aUTkZ4952eLXXXmN3quqQQQtV1eye+/PHlqmqy4AdepqeMTVlSpIkzRyj0qMnSZKkKTb0Hr2qWgxsN+w6JEmSusYePUmSpI4y6EmSJHWUQU+SJKmjDHqSJEkdNfSTMUbRahs+lA1fdPiwy5AkSVou9uhJkiR1lEFPkiSpowx6kiRJHWXQkyRJ6ihPxhjgnhv/yA3fOXbYZUjSjLPBMw4edgmSetijJ0mS1FEGPUmSpI4y6EmSJHWUQU+SJKmjDHqSJEkdZdCTJEnqqBkR9JIcluRlU7SuxUk2nop1SZIkjbIZcR29qvr0sGuQJEmaaYbWo5fkf5MsSHJRkkPbabckeW+S85OcnWSTdvqRSY5o75+a5ENJTk9ycZLdknwtyS+S/MtE65ckSVqZDHPo9hVVtSswBzg8yUbAOsDZVbUjcDrwqnGWvbOqngx8GvgG8DpgO+CQdj3jrV+SJGmlMcygd3iS84GzgUcCjwXuBL7Vzl8AzB5n2RPb20XARVV1dVXdAVzermu89Y8ryaFJ5ieZf+2NNy/jLkmSJI2OoQS9JHsB+wFz296784BZwF1VVW2zexj/GMI72tt7e+6PPV5tgvWPq6rmVdWcqpqz8frrLe0uSZIkjZxh9eitD1xfVX9KsjXwxBm2fkmSpJE3rKD3PZqetwuA99AMr86k9UuSJI283DdSqjE7P3aL+tFHjhx2GZI042zwjIOHXYK00kmyoKrmDJo3Iy6YLEmSpKVn0JMkSeoog54kSVJHGfQkSZI6yqAnSZLUUQY9SZKkjhrvmydWaquuv5GXCJAkSTOePXqSJEkdZdCTJEnqKIOeJElSRxn0JEmSOsqgJ0mS1FGedTvAvbfcwM1nnjjsMiSpE9bb/dnDLkFaadmjJ0mS1FEGPUmSpI4y6EmSJHWUQU+SJKmjDHqSJEkdtVIEvSSnJpkz7DokSZKmU+eDXpJVh12DJEnSMMyIoJdkdpJLkhyb5IIkJyRZO8m+Sc5LsijJUUnWbNsvTvLOJD8Gnt+znlXadfzL0HZGkiRpmsyIoNfaCphXVTsANwFvAo4BXlhV29Nc/Pk1Pe1vr6o9qupL7ePVgOOBy6rq7dNXtiRJ0nDMpKB3ZVWd2d4/DtgXuKKqLmunHQs8uaf9l/uW/wxwYVW9d9DKkxyaZH6S+dfecNNU1i1JkjQUMyno1VK2v7Xv8U+AvZPMGrjyqnlVNaeq5my8wYOWqUBJkqRRMpOC3uZJ5rb3Xwz8AJid5DHttL8BTptg+c8B3wG+ksTv+JUkSZ03k4LexcDBSS4ANgQ+BLycJrgtAu4FPj3RCqrqg8C5wBeSzKR9lyRJWmozqWfr3qo6rG/aKcDO/Q2ranbf47167r9rRRQnSZI0auzVkiRJ6qgZ0aNXVYuB7YZdhyRJ0kxij54kSVJHGfQkSZI6yqAnSZLUUQY9SZKkjpoRJ2NMt1XW3YD1dn/2sMuQJElaLvboSZIkdZRBT5IkqaMMepIkSR1l0JMkSeoog54kSVJHedbtAPfedgt/uuCMYZchSSuNtXfYc9glSJ1kj54kSVJHGfQkSZI6yqAnSZLUUQY9SZKkjjLoSZIkdZRBT5IkqaNGIugl+cmwa5AkSeqaaQl6SSa8Xl9VPWlFb0OSJGlls9RBL8nLklyQ5PwkX0jyrCQ/TXJekh8k2aRtd2SSeUlOBj7fPj4qyalJLk9yeM86b2lvv5zkGT3Tj0nyvCSzkhydZFG7nb3b+Yck+UqSbwInJ1mn3cY5bbsD2nbbJvlZkoVt7Y9dvqdNkiRp9C1VL1iSbYG3AbtX1bVJNgQKeGJVVZK/Bd4M/EO7yK7AHlV1W5Ijga2BvYH1gEuTfKqq7urZxJeAFwLfSbIGsC/wGuB1AFW1fZKtaULd49pl5gI7VNV1Sf4V+GFVvSLJBsDPkvwAOAz4SFUd36531aXZb0mSpJloaYc79wFOqKprAdpwtT3w5SSbAmsAV/S0P7Gqbut5/O2qugO4I8k1wCbAb3vmfxf4aJI1gacBp7chcQ/gY+02L0nya2As6H2/qq5r7+8PPDvJEe3jWcDmwFnA25I8AvhaVf2if8eSHAocCvDITTdZyqdFkiRp9Czt0G1oevB6fQz4eFVtD7yaJlyNubWv7R099++hL2hW1e3AqcBTaXr2vtSz3fH0biPA86pqp/Zn86q6uKr+G3g2cBtwUpJ9+ldSVfOqak5Vzdn4wRtMsDlJkqSZYWmD3inAC5JsBNAO3a4P/K6df/AU1PQl4OXAnsBJ7bTTgYPabT6Oppfu0gHLngS8Pknatju3t48GLq+qjwInAjtMQZ2SJEkjbamCXlVdBLwXOC3J+cAHgSOBryQ5A7h2Cmo6GXgy8IOqurOd9klg1SSLgC8Dh7RDwP3eA6wOXJDkwvYxNL2DFyZZSHOc4OenoE5JkqSRlqr+kVjtsu3W9eMvfnbYZUjSSmPtHfYcdgnSjJVkQVXNGTRvJC6YLEmSpKln0JMkSeoog54kSVJHGfQkSZI6yqAnSZLUUQY9SZKkjlrar0BbKayy1rqe6i9JkmY8e/QkSZI6yqAnSZLUUQY9SZKkjjLoSZIkdZQnYwxQd9zG7VcsGnYZkqSOmLXF9sMuQSspe/QkSZI6yqAnSZLUUQY9SZKkjjLoSZIkdZRBT5IkqaMMepIkSR01I4JekjcmWXs5lj81yZyprEmSJGnUzYigB7wRWOagJ0mStDIauaCXZJ0k305yfpILk7wL2Az4UZIftW32T3JWknOTfCXJuu30dyY5p11uXpL0rXuVJMcm+Zfp3zNJkqTpNXJBD3gacFVV7VhV2wEfBq4C9q6qvZNsDLwd2K+qdgHmA29ql/14Ve3WLrcW8Mye9a4GHA9cVlVvn6Z9kSRJGppRDHqLgP2SvD/JnlV1Y9/8JwLbAGcmWQgcDDyqnbd3kp8mWQTsA2zbs9xngAur6r2DNprk0CTzk8z/w3XXT+X+SJIkDcXIfddtVV2WZFfgGcD7kpzc1yTA96vqxfebmMwCPgnMqaorkxwJzOpp8hOaIPifVXX7gO3OA+YB7Lr9tjVlOyRJkjQkI9ejl2Qz4E9VdRzwH8AuwM3Aem2Ts4Hdkzymbb92ksdxX6i7tj1m78C+VX8O+A7wlSQjF3AlSZKm2igGnu2BDyS5F7gLeA0wF/hukqvb4/QOAb6YZM12mbe3PYGfpRn6XQyc07/iqvpgkvWBLyQ5qKrunYb9kSRJGopUOUrZb9ftt60zT/zSsMuQJHXErC22H3YJ6rAkC6pq4PWCR27oVpIkSVPDoCdJktRRBj1JkqSOMuhJkiR1lEFPkiSpowx6kiRJHTWK19Ebuqy5lqfCS5KkGc8ePUmSpI4y6EmSJHWUQU+SJKmjDHqSJEkd5ckYA9Rdd3DX/10x7DIkSSup1R+2xbBLUEfYoydJktRRBj1JkqSOMuhJkiR1lEFPkiSpowx6kiRJHWXQkyRJ6qiRC3pJvpNkgySzk1w47HokSZJmqpEKekkCPLOqbhh2LZIkSTPd0INe23N3cZJPAucC9yTZuJ29WpJjk1yQ5IQka7fL7JrktCQLkpyUZNMkWyY5t2e9j02yYLz2076jkiRJ02zoQa+1FfD5qtoZ+HXf9HlVtQNwE/DaJKsDHwMOrKpdgaOA91bVr4Abk+zULvty4Jjx2k/HTkmSJA3TqHwF2q+r6uwB06+sqjPb+8cBhwPfA7YDvt+M9LIqcHXb5r+Alyd5E/BC4Ak0YXG89n+W5FDgUIDNH77Z1OyVJEnSEI1K0Lt1nOk14HGAi6pq7oD2XwXeBfwQWFBVf0yy2QTt71tx1TxgHsCuO27fv11JkqQZZ1SGbsezeZKxgPZi4MfApcBDxqYnWT3JtgBVdTtwEvAp4Oh2uXHbS5IkddmoB72LgYOTXABsCHyqqu4EDgTen+R8YCHwpJ5ljqfp+TsZYBLtJUmSOmnoQ7dVtZjmGLqxx7Pbu9cC24yzzELgyeOscg/gqKq6Z5LtJUmSOmnoQW8qJfk6sCWwz7BrkSRJGrZOBb2qeu6wa5AkSRoVo36MniRJkpaRQU+SJKmjDHqSJEkdZdCTJEnqqE6djDFVsvqarP6wLYZdhiRJ0nKxR0+SJKmjDHqSJEkdZdCTJEnqKIOeJElSR3kyxgB1z13cff3vh12GJEmawVZ78CbDLsEePUmSpK4y6EmSJHWUQU+SJKmjDHqSJEkdZdCTJEnqKIOeJElSR61UQS/JkUmOGHYdkiRJ02Hkgl4Sr+0nSZI0BaY96CV5R5JLknw/yReTHJHk1CT/muQ04A1J9k1yXpJFSY5Ksma77OIkG7f35yQ5tb1/ZNvu1CSXJzm8Z3tvS3Jpkh8AW033/kqSJA3LtPaeJZkDPA/Yud32ucCCdvYGVfWUJLOAXwD7VtVlST4PvAb48BJWvzWwN7AecGmSTwE7AC8aZ3uSJEmdNt09ensA36iq26rqZuCbPfO+3N5uBVxRVZe1j48FnjyJdX+7qu6oqmuBa4BNgD2Br1fVn6rqJuDE8RZOcmiS+UnmX3vtdUu5W5IkSaNnuoNeJph36yTa3M19Nc/qm3dHz/17uK+3siZTWFXNq6o5VTVn4403nMwikiRJI226g96PgWclmZVkXeCvBrS5BJid5DHt478BTmvvLwZ2be8/bxLbOx14bpK1kqwHPGuZK5ckSZphpjXoVdU5NMOn5wNfA+YDN/a1uR14OfCVJIuAe4FPt7PfDXwkyRk0vXZL2t65NEPCC4GvAmdMyY5IkiTNAKma1Mjm1G0wWbeqbkmyNk2P26FtIBsZu+68Y/30hycPuwxJkjSDrfbgTaZlO0kWVNWcgTVMSwX3Ny/JNjTH2B07aiFPkiSpK6Y96FXVS6Z7m5IkSSujkftmDEmSJE0Ng54kSVJHGfQkSZI6yqAnSZLUUcM463bkZdXVp+2UaEmSpBXFHj1JkqSOMuhJkiR11LR/M8ZMkORm4NJh16FxbQxcO+wiNCFfo9Hm6zPafH1G2yi+Po+qqocMmuExeoNdOt5XiWj4ksz39RltvkajzddntPn6jLaZ9vo4dCtJktRRBj1JkqSOMugNNm/YBWhCvj6jz9dotPn6jDZfn9E2o14fT8aQJEnqKHv0JEmSOsqg1yfJ05JcmuSXSd4y7Hp0nySPTPKjJBcnuSjJG4Zdkx4oyapJzkvyrWHXovtLskGSE5Jc0n6O5g67Jt1fkr9vf79dmOSLSWYNu6aVWZKjklyT5MKeaRsm+X6SX7S3Dx5mjUti0OuRZFXgE8DTgW2AFyfZZrhVqcfdwD9U1eOBJwKv8/UZSW8ALh52ERroI8D3qmprYEd8nUZKkocDhwNzqmo7YFXgRcOtaqV3DPC0vmlvAU6pqscCp7SPR5ZB7/6eAPyyqi6vqjuBLwEHDLkmtarq6qo6t71/M80fqYcPtyr1SvII4K+A/xp2Lbq/JA8Cngx8DqCq7qyqG4ZalAZZDVgryWrA2sBVQ65npVZVpwPX9U0+ADi2vX8s8JzprGlpGfTu7+HAlT2Pf4tBYiQlmQ3sDPx0yKXo/j4MvBm4d8h16IEeDfwBOLodWv+vJOsMuyjdp6p+B/wH8BvgauDGqjp5uFVpgE2q6mpoOiCAhw65ngkZ9O4vA6Z5WvKISbIu8FXgjVV107DrUSPJM4FrqmrBsGvRQKsBuwCfqqqdgVsZ8SGnlU17rNcBwBbAZsA6SV463Ko00xn07u+3wCN7Hj8Cu81HSpLVaULe8VX1tWHXo/vZHXh2ksU0hz3sk+S44ZakHr8FfltVY73gJ9AEP42O/YArquoPVXUX8DXgSUOuSQ/0+ySbArS31wy5ngkZ9O7vHOCxSbZIsgbNQbAnDrkmtZKE5viii6vqg8OuR/dXVW+tqkdU1Wyaz84Pq8reiBFRVf8HXJlkq3bSvsDPh1iSHug3wBOTrN3+vtsXT5gZRScCB7f3Dwa+McRalmi1YRcwSqrq7iR/B5xEc7bTUVV10ZDL0n12B/4GWJRkYTvtn6vqO8MrSZpRXg8c3/4jeznw8iHXox5V9dMkJwDn0lxl4Dxm2LcwdE2SLwJ7ARsn+S3wLuDfgP9J8kqacP784VW4ZH4zhiRJUkc5dCtJktRRBj1JkqSOMuhJkiR1lEFPkiSpowx6kiRJHWXQk6QRkGTNJD9IsjDJC4ddj6Ru8Dp6kjQadgZWr6qdhl2IpO6wR0+SpkCSlyW5IMn5Sb6Q5FFJTmmnnZJk87bdQ5J8Nck57c/uSR4KHAfs1PbobTncvZHUFV4wWZKWU5Jtab6XdPequjbJhsCxwAlVdWySVwDPrqrnJPlv4JNV9eM2/J1UVY9PshdwRFU9c1j7Ial7HLqVpOW3D02ouxagqq5LMhf463b+F4B/b+/vB2zTfJUpAA9Kst50Fitp5WHQk6TlF2BJwyNj81cB5lbVbfdbwX3BT5KmjMfoSdLyOwV4QZKNANqh258AL2rnHwT8uL1/MvB3Ywsm2Wn6ypS0srFHT5KWU1VdlOS9wGlJ7gHOAw4Hjkryj8AfgJe3zQ8HPpHkAprfwacDhw2hbEkrAU/GkCRJ6iiHbiVJkjrKoCdJktRRBj1JkqSOMuhJkiR1lEFPkiSpowx6kiRJHWXQkyRJ6iiDniRJUkf9f8NhhP4A1l4tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data=top_zerocarb_coefs, x=top_zerocarb_coefs['coef'], y='ngram', palette='Reds_r')\n",
    "plt.ylabel('')\n",
    "plt.title('Top 20 Ngrams Correlated with r/zerocarb', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03556896",
   "metadata": {},
   "source": [
    "After removing the word 'woe', we can see that the rest of our observations from earlier hold true. Those observations are:\n",
    "\n",
    "From the above chart, we can see that the top words associated with our best model for `r/keto` mentions no diet terminologies, and is mainly made up of words for meat items, e.g. 'ground', 'steaks', 'lamb', 'pork'. A reason why '30 days' is on the list here, is because a social media influencer, ['Dr. Shawn Baker', encouraged people to do a 30 Day Carnivore diet challenge in April of 2020.](https://twitter.com/sbakermd/status/1243546540829859840?lang=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4796d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16614c74",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dca981",
   "metadata": {},
   "source": [
    "Let's create a DataFrame to look closer at the posts that were misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "6e198ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r/keto         0\n",
       "r/zerocarb     0\n",
       "c_text         0\n",
       "is_zerocarb    0\n",
       "predicted      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creation of dataframe with probabilities as well as predictions vs actual\n",
    "\n",
    "class_prob = pd.DataFrame(tvec_lr_gs_V6.predict_proba(X_test),\n",
    "                          columns=['r/keto', 'r/zerocarb'])\n",
    "\n",
    "class_prob['c_text'] = X_test.tolist()\n",
    "class_prob['is_zerocarb'] = y_test.tolist()\n",
    "class_prob['predicted'] = tvec_lr_gs_V6.predict(X_test)\n",
    "class_prob.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "65296229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the two DataFrames, 1 for keto and 1 for zerocarb\n",
    "misclass_zerocarb = class_prob[(class_prob['is_zerocarb'] == 1) & ((class_prob['predicted'] == 0))]\n",
    "misclass_keto = class_prob[(class_prob['is_zerocarb'] == 0) & ((class_prob['predicted'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "d366a623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r/keto</th>\n",
       "      <th>r/zerocarb</th>\n",
       "      <th>c_text</th>\n",
       "      <th>is_zerocarb</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>can you think of something animal based zc fri...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>tldr does anyone have an intolerance to ground...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>6 days ago i posted about issues of frequentin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>i have decided that lamb is the superior anima...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>been eating ground beef ground pork bacon and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>hi all i have a question i'm dying to hear if ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>to make the life easier for people feel free t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>i found a farmer not too far away from where i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>my source of ground beef is very lean probably...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>i've upped my ribeye intake to 3lb a day and m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        r/keto  r/zerocarb                                             c_text  \\\n",
       "2173  0.000019    0.999981  can you think of something animal based zc fri...   \n",
       "1796  0.000111    0.999889  tldr does anyone have an intolerance to ground...   \n",
       "3892  0.000113    0.999887  6 days ago i posted about issues of frequentin...   \n",
       "896   0.000283    0.999717  i have decided that lamb is the superior anima...   \n",
       "419   0.000354    0.999646  been eating ground beef ground pork bacon and ...   \n",
       "3318  0.000373    0.999627  hi all i have a question i'm dying to hear if ...   \n",
       "3824  0.000446    0.999554  to make the life easier for people feel free t...   \n",
       "1250  0.000606    0.999394  i found a farmer not too far away from where i...   \n",
       "2603  0.000616    0.999384  my source of ground beef is very lean probably...   \n",
       "998   0.000635    0.999365  i've upped my ribeye intake to 3lb a day and m...   \n",
       "\n",
       "      is_zerocarb  predicted  \n",
       "2173            1          1  \n",
       "1796            1          1  \n",
       "3892            1          1  \n",
       "896             1          1  \n",
       "419             1          1  \n",
       "3318            1          1  \n",
       "3824            1          1  \n",
       "1250            1          1  \n",
       "2603            1          1  \n",
       "998             1          1  "
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prob.sort_values('r/zerocarb', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "88d1c745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r/keto</th>\n",
       "      <th>r/zerocarb</th>\n",
       "      <th>c_text</th>\n",
       "      <th>is_zerocarb</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.997156</td>\n",
       "      <td>so tomorrow i am making my first ever bone bro...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>0.011134</td>\n",
       "      <td>0.988866</td>\n",
       "      <td>i've started eating canned cod liver every tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.984149</td>\n",
       "      <td>so i am looking to start keto and i know i wan...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>0.022497</td>\n",
       "      <td>0.977503</td>\n",
       "      <td>so does it matter if it is from a cow a goat a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.023091</td>\n",
       "      <td>0.976909</td>\n",
       "      <td>hey pals i love steak but like every single ri...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>0.026650</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>tips with the cuts would fit into the lean cat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>0.046326</td>\n",
       "      <td>0.953674</td>\n",
       "      <td>i cant eat any sort of dairy it gives me sever...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.052120</td>\n",
       "      <td>0.947880</td>\n",
       "      <td>that would be hyperbole on anybody else but i'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>0.052252</td>\n",
       "      <td>0.947748</td>\n",
       "      <td>for my whole life i have been trained to think...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.053211</td>\n",
       "      <td>0.946789</td>\n",
       "      <td>i am both omad and keto the omad community is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        r/keto  r/zerocarb                                             c_text  \\\n",
       "2230  0.002844    0.997156  so tomorrow i am making my first ever bone bro...   \n",
       "1736  0.011134    0.988866  i've started eating canned cod liver every tim...   \n",
       "3450  0.015851    0.984149  so i am looking to start keto and i know i wan...   \n",
       "3743  0.022497    0.977503  so does it matter if it is from a cow a goat a...   \n",
       "71    0.023091    0.976909  hey pals i love steak but like every single ri...   \n",
       "2169  0.026650    0.973350  tips with the cuts would fit into the lean cat...   \n",
       "2427  0.046326    0.953674  i cant eat any sort of dairy it gives me sever...   \n",
       "2498  0.052120    0.947880  that would be hyperbole on anybody else but i'...   \n",
       "3758  0.052252    0.947748  for my whole life i have been trained to think...   \n",
       "670   0.053211    0.946789  i am both omad and keto the omad community is ...   \n",
       "\n",
       "      is_zerocarb  predicted  \n",
       "2230            0          1  \n",
       "1736            0          1  \n",
       "3450            0          1  \n",
       "3743            0          1  \n",
       "71              0          1  \n",
       "2169            0          1  \n",
       "2427            0          1  \n",
       "2498            0          1  \n",
       "3758            0          1  \n",
       "670             0          1  "
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass_keto.sort_values('r/zerocarb', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "aeeec4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i am both omad and keto the omad community is freaked the fuck out by what i eat usually people are freaked out by omad itself but i can freak out the people that freak other people out so here is my meal today  i am doing an experiment to see the reaction of each of these subreddits that is one big ass steak and 4 eggs covered in grass fed butter bacon a chunk of aged cheese and sardines i am stuffed and happy i don't really know the calories or the macros i know its a ton of fat and protein and most of that fat is saturated although i cooked the eggs in evoo as far as i am concerned this is the one of the healthiest meals i can eat but go ahead and criticize i am curious tasty keto meal\""
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to cycle through the index of False Positives\n",
    "misclass_keto.loc[670, 'c_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b24458",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b8b8e",
   "metadata": {},
   "source": [
    "From the above table, we can see that the model does have a pretty good grasp on posts talking about meats, ribeyes, ground beef, lean, animal organs, bones etc.\n",
    "\n",
    "The posts that use this kind of language, invariably get classified as `r/zerocarb` sometimes wrongly. Other topics that will get classified as `r/zerocarb` are: Mentions newbie, discussing butchers in different areas, fatty food, and the [30 day challenge by Dr. Shawn Baker.](https://twitter.com/sbakermd/status/1243546540829859840?lang=en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "d2985fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r/keto</th>\n",
       "      <th>r/zerocarb</th>\n",
       "      <th>c_text</th>\n",
       "      <th>is_zerocarb</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>hello keto friends i have done dirty keto in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>currently doing 1268 calories 33 deficit fat 8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>hello friends tldr keto is going well but i ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>hi yall long time lurker but thanks to this th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>0.999295</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>10 years ago i was 5'6 and 240 lbs then i had ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0.999251</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>hello all alfie isn't my name and keto is beco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>0.999076</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>start weight 309lb current weight 297 time on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>0.998848</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>started keto 3 weeks ago at 307 and i'm down t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.998815</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>first time poster and im looking for some sugg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>0.998776</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>i went all in on my weight loss last october a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        r/keto  r/zerocarb                                             c_text  \\\n",
       "3205  0.999774    0.000226  hello keto friends i have done dirty keto in t...   \n",
       "2956  0.999643    0.000357  currently doing 1268 calories 33 deficit fat 8...   \n",
       "1776  0.999509    0.000491  hello friends tldr keto is going well but i ne...   \n",
       "1457  0.999453    0.000547  hi yall long time lurker but thanks to this th...   \n",
       "3609  0.999295    0.000705  10 years ago i was 5'6 and 240 lbs then i had ...   \n",
       "3246  0.999251    0.000749  hello all alfie isn't my name and keto is beco...   \n",
       "2563  0.999076    0.000924  start weight 309lb current weight 297 time on ...   \n",
       "1041  0.998848    0.001152  started keto 3 weeks ago at 307 and i'm down t...   \n",
       "159   0.998815    0.001185  first time poster and im looking for some sugg...   \n",
       "1880  0.998776    0.001224  i went all in on my weight loss last october a...   \n",
       "\n",
       "      is_zerocarb  predicted  \n",
       "3205            0          0  \n",
       "2956            0          0  \n",
       "1776            0          0  \n",
       "1457            0          0  \n",
       "3609            0          0  \n",
       "3246            0          0  \n",
       "2563            0          0  \n",
       "1041            0          0  \n",
       "159             0          0  \n",
       "1880            0          0  "
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prob.sort_values('r/keto', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "b7304f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r/keto</th>\n",
       "      <th>r/zerocarb</th>\n",
       "      <th>c_text</th>\n",
       "      <th>is_zerocarb</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>0.982741</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>have been on lowcarb keto for over a year lost...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.020244</td>\n",
       "      <td>i am 278 as of today iv already lost 40ish lbs...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.977588</td>\n",
       "      <td>0.022412</td>\n",
       "      <td>i have a bmi of 175 i currently want to cut on...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>will it hurt my exercise performance its 228g ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.976533</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>hey all i was playing around with data from th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>0.966528</td>\n",
       "      <td>0.033472</td>\n",
       "      <td>back story i have pvc caused by an electrical ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>0.956542</td>\n",
       "      <td>0.043458</td>\n",
       "      <td>ive been low to no carb now since late aprilea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>0.956153</td>\n",
       "      <td>0.043847</td>\n",
       "      <td>been tracking what i eat for 3 weeks and aimin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>0.949903</td>\n",
       "      <td>0.050097</td>\n",
       "      <td>all right guys i dont know where else to ask y...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>0.949748</td>\n",
       "      <td>0.050252</td>\n",
       "      <td>just went to the doctor to get some blood work...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        r/keto  r/zerocarb                                             c_text  \\\n",
       "2525  0.982741    0.017259  have been on lowcarb keto for over a year lost...   \n",
       "576   0.979756    0.020244  i am 278 as of today iv already lost 40ish lbs...   \n",
       "957   0.977588    0.022412  i have a bmi of 175 i currently want to cut on...   \n",
       "3244  0.977143    0.022857  will it hurt my exercise performance its 228g ...   \n",
       "78    0.976533    0.023467  hey all i was playing around with data from th...   \n",
       "2419  0.966528    0.033472  back story i have pvc caused by an electrical ...   \n",
       "3203  0.956542    0.043458  ive been low to no carb now since late aprilea...   \n",
       "2242  0.956153    0.043847  been tracking what i eat for 3 weeks and aimin...   \n",
       "3216  0.949903    0.050097  all right guys i dont know where else to ask y...   \n",
       "3763  0.949748    0.050252  just went to the doctor to get some blood work...   \n",
       "\n",
       "      is_zerocarb  predicted  \n",
       "2525            1          0  \n",
       "576             1          0  \n",
       "957             1          0  \n",
       "3244            1          0  \n",
       "78              1          0  \n",
       "2419            1          0  \n",
       "3203            1          0  \n",
       "2242            1          0  \n",
       "3216            1          0  \n",
       "3763            1          0  "
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to cycle through the index of False Positives\n",
    "misclass_zerocarb.sort_values('r/keto', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "b32d2983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all right guys i dont know where else to ask you should know about this basically im staring a bulk soon and i dont want to stay zerocarb for that time should i just go full on high carb with rice and shit ton of pasta or stay mostly zero carb but still a decent amount of carbs in form of peanut butter protein shakesbars and some fruitsveggies and a bit of grain is it worth staying mostly meat if youre not fully zero carb'"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to cycle through the index of False Positives\n",
    "misclass_zerocarb.loc[3216, 'c_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e4d17",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db2c37",
   "metadata": {},
   "source": [
    "From the above table, we can see that the model does have a pretty good grasp on posts talking about meats, ribeyes, ground beef, lean, animal organs, bones etc.\n",
    "\n",
    "The posts that use this kind of language, invariably get classified as `r/zerocarb` sometimes wrongly. Other topics that will get classified as `r/zerocarb` are: Mentions newbie, discussing butchers in different areas, fatty food, and the [30 day challenge by Dr. Shawn Baker.](https://twitter.com/sbakermd/status/1243546540829859840?lang=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64a9d4",
   "metadata": {},
   "source": [
    "# Model Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3d690",
   "metadata": {},
   "source": [
    "Let us start by recapping our problem statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf41e25",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952fd99",
   "metadata": {},
   "source": [
    "We are concerned that misclassification of clients into certain diet models will result in a rebound that deproves their health and fitness, also affecting motivation to get back into shape in the future. This is especially the case for highly motivated individuals, who go hard into pursuing a 'Zerocarb/Carnivore' diet, and crash or rebound after. The effects of the rebound can lead to worse weight gain, to the point the individual is unhealthier than when they started.\n",
    "\n",
    "So the goal of the model is to reduce False Positives, i.e. classifying clients into `zerocarb` wrongly when they should have been in the `keto` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46c01c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d6dbc",
   "metadata": {},
   "source": [
    "As shown by the tables and charts above, our model is able to grasp mentions of 'bone broth', 'meat', 'ground beef' and other similar words. Mentions of improved health, e.d. reduced blood pressure also end up classified as `zerocarb`.\n",
    "\n",
    "However our model is thrown off by mentions of animal organs and the word bone specifically. The context of the words can be different, and they might be relevant to both `keto` and `zerocarb`, however as long as the post contains these words, it will most likely be classfied as `zerocarb`. \n",
    "\n",
    "Even though both `r/keto` and `r/zerocarb` are both very similar in the sense that they are both proponents of high protein, high fat, and low/no carb diets and lifestyle, the `r/zerocarb` definitely has a much larger focus on meat(especially beef), animal organs, and bones (bone broth)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91caccf3",
   "metadata": {},
   "source": [
    "### Model Improvements and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cb2d5",
   "metadata": {},
   "source": [
    "**Improvements**\n",
    "It is in our interest to reduce False Positives as much as possible, as such, we would prefer to maximize the `precision` score of the model as much as possible.<br>\n",
    "1. One way we can do this is test other models such as support vector machines, and perhaps deep learning models as well.\n",
    "2. Another way we can do this is to adjust the threshold for the classification of `zerocarb`, making this an imbalanced classification. This will require further investigation as we continue to improve the model. <br>\n",
    "3. Lastly, we can include other features in our model, other than just text, sentiment analysis for example, could possible improve the classification score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89964efc",
   "metadata": {},
   "source": [
    "**Recommendations**\n",
    "1. Our current model performs 2% better than our baseline model on accuracy. As such we would reccommend using this model for classification. \n",
    "2. For those model probabilities where the classification is boderline, e.g. 51% vs 49%, we would recommend classifiying those as `keto`, as it is easier to make the jump from `keto` to `zerocarb` if the client still wants to do so.\n",
    "3. Lastly, we would also recommend reviewing those clients within one month of being put on the `zerocarb` diet. If we review them within one month and find that the diet is not working, it might not be too late to move them to `keto` diets and prevent a rebound from happening."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
